{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412690dd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:23.412808Z",
     "iopub.status.busy": "2024-10-28T19:37:23.412460Z",
     "iopub.status.idle": "2024-10-28T19:37:31.374497Z",
     "shell.execute_reply": "2024-10-28T19:37:31.373527Z"
    },
    "papermill": {
     "duration": 7.972482,
     "end_time": "2024-10-28T19:37:31.376772",
     "exception": false,
     "start_time": "2024-10-28T19:37:23.404290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0b8656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.390580Z",
     "iopub.status.busy": "2024-10-28T19:37:31.390149Z",
     "iopub.status.idle": "2024-10-28T19:37:31.394303Z",
     "shell.execute_reply": "2024-10-28T19:37:31.393480Z"
    },
    "papermill": {
     "duration": 0.012999,
     "end_time": "2024-10-28T19:37:31.396211",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.383212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e7ce2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.410234Z",
     "iopub.status.busy": "2024-10-28T19:37:31.409583Z",
     "iopub.status.idle": "2024-10-28T19:37:31.659228Z",
     "shell.execute_reply": "2024-10-28T19:37:31.658369Z"
    },
    "papermill": {
     "duration": 0.259368,
     "end_time": "2024-10-28T19:37:31.661824",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.402456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3048c983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.676097Z",
     "iopub.status.busy": "2024-10-28T19:37:31.675787Z",
     "iopub.status.idle": "2024-10-28T19:37:31.694532Z",
     "shell.execute_reply": "2024-10-28T19:37:31.693664Z"
    },
    "papermill": {
     "duration": 0.02779,
     "end_time": "2024-10-28T19:37:31.696369",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.668579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Men Tshirts', 'Sarees', 'Kurtis', 'Women Tshirts',\n",
       "       'Women Tops & Tunics'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1ab9a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.711038Z",
     "iopub.status.busy": "2024-10-28T19:37:31.710759Z",
     "iopub.status.idle": "2024-10-28T19:37:31.786296Z",
     "shell.execute_reply": "2024-10-28T19:37:31.785616Z"
    },
    "papermill": {
     "duration": 0.084691,
     "end_time": "2024-10-28T19:37:31.788303",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.703612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_c1 = df_train[df_train['Category'] == 'Men Tshirts']\n",
    "df_c2 = df_train[df_train['Category'] == 'Sarees']\n",
    "df_c3 = df_train[df_train['Category'] == 'Kurtis']\n",
    "df_c4 = df_train[df_train['Category'] == 'Women Tshirts']\n",
    "df_c5 = df_train[df_train['Category'] == 'Women Tops & Tunics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3e7add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.801863Z",
     "iopub.status.busy": "2024-10-28T19:37:31.801547Z",
     "iopub.status.idle": "2024-10-28T19:37:31.818509Z",
     "shell.execute_reply": "2024-10-28T19:37:31.817741Z"
    },
    "papermill": {
     "duration": 0.025855,
     "end_time": "2024-10-28T19:37:31.820436",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.794581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>default</td>\n",
       "      <td>round</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>default</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Category  len      attr_1 attr_2   attr_3   attr_4         attr_5  \\\n",
       "0   0  Men Tshirts    5     default  round  printed  default  short sleeves   \n",
       "1   1  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
       "2   2  Men Tshirts    5     default   polo    solid    solid  short sleeves   \n",
       "3   3  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
       "4   4  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n",
       "\n",
       "  attr_6 attr_7 attr_8 attr_9 attr_10  \n",
       "0    NaN    NaN    NaN    NaN     NaN  \n",
       "1    NaN    NaN    NaN    NaN     NaN  \n",
       "2    NaN    NaN    NaN    NaN     NaN  \n",
       "3    NaN    NaN    NaN    NaN     NaN  \n",
       "4    NaN    NaN    NaN    NaN     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db2513db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.834695Z",
     "iopub.status.busy": "2024-10-28T19:37:31.834435Z",
     "iopub.status.idle": "2024-10-28T19:37:31.858940Z",
     "shell.execute_reply": "2024-10-28T19:37:31.858131Z"
    },
    "papermill": {
     "duration": 0.033943,
     "end_time": "2024-10-28T19:37:31.860835",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.826892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelEncoderDict:\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        \n",
    "    def fit(self, df, columns):\n",
    "        \"\"\"Fit label encoders for each column\"\"\"\n",
    "        for col in columns:\n",
    "            le = LabelEncoder()\n",
    "            # Include NaN as a unique label by appending it to valid labels\n",
    "            valid_labels = df[col].dropna().unique().tolist()\n",
    "            valid_labels.append('NaN')  # Assign a label for NaN\n",
    "            le.fit(valid_labels)\n",
    "            self.encoders[col] = le\n",
    "            \n",
    "    def transform(self, df, columns):\n",
    "        \"\"\"Transform labels using fitted encoders\"\"\"\n",
    "        encoded = np.zeros((len(df), len(columns)))\n",
    "        for i, col in enumerate(columns):\n",
    "            series = df[col].copy()\n",
    "            # Replace NaNs with the string 'NaN' so they can be encoded\n",
    "            series = series.fillna('NaN')\n",
    "            encoded[:, i] = self.encoders[col].transform(series)\n",
    "        return encoded\n",
    "    \n",
    "    def get_num_classes(self, column):\n",
    "        \"\"\"Get number of classes for a specific column\"\"\"\n",
    "        return len(self.encoders[column].classes_)\n",
    "\n",
    "\n",
    "class MultiLabelImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform_basic=None, transform_augmented=None, attr_columns=10,do_transform=True):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform_basic = transform_basic  # Basic transform without augmentation\n",
    "        self.transform_augmented = transform_augmented  # Augmented transform with augmentation\n",
    "        self.attr_columns = attr_columns\n",
    "        self.do_transform = do_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path\n",
    "        img_name = str(self.df.iloc[idx]['id']).zfill(6)\n",
    "        img_path = os.path.join(self.image_dir, f\"{img_name}.jpg\")\n",
    "\n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (512,512))\n",
    "\n",
    "        # Apply random probability to choose between augmentation or notF\n",
    "        if (random.random() > 0.5) and self.do_transform:\n",
    "            if self.transform_basic:\n",
    "                image = self.transform_basic(image)\n",
    "        else:\n",
    "            if self.transform_augmented:\n",
    "                image = self.transform_augmented(image)\n",
    "\n",
    "        # Ensure labels are integers and convert to tensor\n",
    "        labels = torch.tensor(self.df.iloc[idx][self.attr_columns].astype(int).values, dtype=torch.long)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "\n",
    "def prepare_data(df, image_dir, batch_size=32, test_size=0.2, num_attr_columns=10):\n",
    "    \"\"\"\n",
    "    Prepare data loaders and label encoders\n",
    "    \"\"\"\n",
    "    # Define attribute columns\n",
    "    attr_columns = [f'attr_{i}' for i in range(1, num_attr_columns+1)] # TODO: Changes with the number of column to consider\n",
    "    \n",
    "    # Create and fit label encoders\n",
    "    label_encoders = LabelEncoderDict()\n",
    "    label_encoders.fit(df, attr_columns)\n",
    "    \n",
    "    # Transform labels\n",
    "    encoded_labels = label_encoders.transform(df, attr_columns)\n",
    "    df_encoded = df.copy()\n",
    "    for i, col in enumerate(attr_columns):\n",
    "        df_encoded[col] = encoded_labels[:, i]\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df = train_test_split(df_encoded, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512,512)),  # TODO: Changes with (512, 512)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    transform_augmented = transforms.Compose([\n",
    "    transforms.Resize((512,512)), \n",
    "    transforms.RandomRotation(degrees=15),  # Rotate by up to 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0)),  # Randomly crop and resize\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),  # Apply perspective distortion\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),  # Affine transformations\n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # Apply random Gaussian blur\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize based on ImageNet statistics\n",
    "    ])\n",
    "    # Create datasets\n",
    "    train_dataset = MultiLabelImageDataset(\n",
    "        train_df,\n",
    "        image_dir,\n",
    "        transform_basic=transform,\n",
    "        transform_augmented = transform_augmented,\n",
    "        attr_columns=attr_columns\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultiLabelImageDataset(\n",
    "        val_df,\n",
    "        image_dir,\n",
    "        transform_basic=transform,\n",
    "        transform_augmented = transform_augmented,\n",
    "        attr_columns=attr_columns,\n",
    "        do_transform = False\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Get number of classes for each attribute\n",
    "    num_classes_per_attr = [label_encoders.get_num_classes(col) for col in attr_columns]\n",
    "    \n",
    "    return train_loader, val_loader, label_encoders, num_classes_per_attr\n",
    "\n",
    "class MultiLabelCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelCELoss, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # outputs is a list of predictions for each label\n",
    "        # targets is a tensor of shape (batch_size, num_labels)\n",
    "        loss = 0\n",
    "        for i, output in enumerate(outputs):\n",
    "            loss += self.criterion(output, targets[:, i])\n",
    "        return loss / len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1d6378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:31.875362Z",
     "iopub.status.busy": "2024-10-28T19:37:31.875063Z",
     "iopub.status.idle": "2024-10-28T19:37:33.644547Z",
     "shell.execute_reply": "2024-10-28T19:37:33.643610Z"
    },
    "papermill": {
     "duration": 1.779751,
     "end_time": "2024-10-28T19:37:33.646942",
     "exception": false,
     "start_time": "2024-10-28T19:37:31.867191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from tqdm import tqdm \n",
    "from transformers import ConvNextModel\n",
    "\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, num_classes_per_attr):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        \n",
    "        # Use ConvNeXt-Base with unfrozen backbone\n",
    "        self.backbone = ConvNextModel.from_pretrained(\"facebook/convnext-base-384-22k-1k\")\n",
    "        backbone_features = self.backbone.config.hidden_sizes[-1]  # 1024 for base model\n",
    "        \n",
    "        # Modified feature processing without fixed dimensions\n",
    "        self.feature_processor = nn.Sequential(\n",
    "            nn.Conv2d(backbone_features, 1024, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Complex classifier heads for each attribute\n",
    "        self.classifier_heads = nn.ModuleList()\n",
    "        for num_classes in num_classes_per_attr:\n",
    "            classifier_head = nn.Sequential(\n",
    "                # First branch - Spatial attention\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(1024, 512, kernel_size=3, padding=1, groups=32),\n",
    "                    nn.GELU(),\n",
    "                    nn.Conv2d(512, 512, kernel_size=3, padding=1, groups=32),\n",
    "                    nn.GELU(),\n",
    "                ),\n",
    "                \n",
    "                # Second branch - Channel attention (SE-like module)\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(512, 128),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(128, 512),\n",
    "                    nn.Sigmoid(),\n",
    "                ),\n",
    "                \n",
    "                # Combine branches and final classification\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(512, 1024),\n",
    "                    nn.LayerNorm(1024),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.LayerNorm(512),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(512, num_classes)\n",
    "                )\n",
    "            )\n",
    "            self.classifier_heads.append(classifier_head)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from ConvNeXt backbone\n",
    "        features = self.backbone(x).last_hidden_state\n",
    "        \n",
    "        # Process features\n",
    "        processed_features = self.feature_processor(features)\n",
    "        \n",
    "        outputs = []\n",
    "        for classifier_head in self.classifier_heads:\n",
    "            # Spatial attention branch\n",
    "            spatial_features = classifier_head[0](processed_features)\n",
    "            \n",
    "            # Channel attention branch\n",
    "            channel_attention = classifier_head[1](spatial_features)\n",
    "            channel_attention = channel_attention.view(-1, 512, 1, 1)\n",
    "            \n",
    "            # Apply channel attention and get final output\n",
    "            attended_features = spatial_features * channel_attention\n",
    "            output = classifier_head[2](attended_features)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "class MultiLabelCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelCELoss, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = 0\n",
    "        for i, output in enumerate(outputs):\n",
    "            loss += self.criterion(output, targets[:, i])\n",
    "        return loss / len(outputs)\n",
    "\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, num_classes_per_attr, model_type):\n",
    "    \n",
    "    model = torch.nn.DataParallel(model)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = MultiLabelCELoss()  # Assuming you have this loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "    # Reduce learning rate on plateau\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    # Early stopping params\n",
    "    early_stopping_patience = 4\n",
    "    early_stopping_counter = 0\n",
    "    best_val_avg_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_predictions = [0] * len(num_classes_per_attr)\n",
    "        total_predictions = 0\n",
    "        overall_correct = 0\n",
    "        \n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", unit=\"batch\") as t:\n",
    "            for images, labels in t:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "                \n",
    "                all_labels_match = torch.ones(labels.size(0), dtype=torch.bool, device=device)\n",
    "                for i, output in enumerate(outputs):\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    correct_predictions[i] += (predicted == labels[:, i]).sum().item()\n",
    "                    all_labels_match &= (predicted == labels[:, i])\n",
    "                    \n",
    "                overall_correct += all_labels_match.sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct_predictions = [0] * len(num_classes_per_attr)\n",
    "        val_total_predictions = 0\n",
    "        val_overall_correct = 0\n",
    "        \n",
    "        with tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", unit=\"batch\") as v:\n",
    "            with torch.no_grad():\n",
    "                for images, labels in v:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    v.set_postfix(loss=loss.item())\n",
    "                    \n",
    "                    all_labels_match_val = torch.ones(labels.size(0), dtype=torch.bool, device=device)\n",
    "                    for i, output in enumerate(outputs):\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        val_correct_predictions[i] += (predicted == labels[:, i]).sum().item()\n",
    "                        all_labels_match_val &= (predicted == labels[:, i])\n",
    "                    \n",
    "                    val_overall_correct += all_labels_match_val.sum().item()\n",
    "                    val_total_predictions += labels.size(0)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        avg_acc = 0\n",
    "        for i in range(len(num_classes_per_attr)):\n",
    "            train_acc = 100 * correct_predictions[i] / total_predictions\n",
    "            val_acc = 100 * val_correct_predictions[i] / val_total_predictions\n",
    "            avg_acc += val_acc\n",
    "            print(f'Attribute {i+1} - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "        avg_acc = avg_acc/(len(num_classes_per_attr))\n",
    "        overall_train_acc = 100 * overall_correct / total_predictions\n",
    "        overall_val_acc = 100 * val_overall_correct / val_total_predictions\n",
    "        print(f'Overall Train Accuracy: {overall_train_acc:.2f}%')\n",
    "        print(f'Overall Validation Accuracy: {overall_val_acc:.2f}%')\n",
    "        \n",
    "        # Early stopping logic based on validation overall accuracy\n",
    "        if avg_acc >= best_val_avg_acc:\n",
    "            best_val_avg_acc = avg_acc\n",
    "            torch.save(model.module.state_dict(), f'best_model_{model_type}.pth')  # Save the best model\n",
    "            early_stopping_counter = 0  # Reset early stopping counter\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        # ReduceLROnPlateau \n",
    "        lr_scheduler.step(overall_val_acc)\n",
    "        \n",
    "        # Check early stopping condition\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "    torch.save(model.module.state_dict(), f'best_model_end_{model_type}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c2d061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:33.661431Z",
     "iopub.status.busy": "2024-10-28T19:37:33.660974Z",
     "iopub.status.idle": "2024-10-28T19:37:33.670541Z",
     "shell.execute_reply": "2024-10-28T19:37:33.669719Z"
    },
    "papermill": {
     "duration": 0.018854,
     "end_time": "2024-10-28T19:37:33.672473",
     "exception": false,
     "start_time": "2024-10-28T19:37:33.653619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "\n",
    "def main(df_c1, df_c2, df_c3, df_c4, df_c5):\n",
    "    # Set image directory\n",
    "    image_dir = '/kaggle/input/train_images'\n",
    "    \n",
    "    # Initialize device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Define a function to train each model sequentially\n",
    "    def train_single_model(data, num_attr_columns, model_type):\n",
    "        # Prepare data\n",
    "        print(f\"Preparing data for {model_type}\")\n",
    "        train_loader, val_loader, label_encoders, num_classes_per_attr = prepare_data(data, image_dir, batch_size=16, num_attr_columns=num_attr_columns)\n",
    "        world_size = torch.cuda.device_count()\n",
    "        # Initialize the model\n",
    "        print(f\"Initializing model {model_type}\")\n",
    "        model = MultiLabelClassifier(num_classes_per_attr).to(device)\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        criterion = MultiLabelCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train the model\n",
    "        print(f\"Training model {model_type}\")\n",
    "        \n",
    "        train_model(model, train_loader, val_loader, num_epochs=40, num_classes_per_attr=num_classes_per_attr, model_type=model_type)\n",
    "        \n",
    "        # Save label encoders\n",
    "        with open(f'label_encoders_{model_type}.pkl', 'wb') as f:\n",
    "            pickle.dump(label_encoders, f)\n",
    "\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"number of classes for {model_type} is {num_classes_per_attr}\")\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "        # Free up memory\n",
    "        del model, train_loader, val_loader, label_encoders, num_classes_per_attr\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Train models one at a time\n",
    "#     train_single_model(df_c1, num_attr_columns=5, model_type=\"c1\")\n",
    "#     train_single_model(df_c2, num_attr_columns=10, model_type=\"c2\")\n",
    "    train_single_model(df_c3, num_attr_columns=9, model_type=\"c3\")\n",
    "#     train_single_model(df_c4, num_attr_columns=8, model_type=\"c4\")\n",
    "#     train_single_model(df_c5, num_attr_columns=10, model_type=\"c5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb73218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T19:37:33.686382Z",
     "iopub.status.busy": "2024-10-28T19:37:33.686109Z",
     "iopub.status.idle": "2024-10-29T06:24:36.534400Z",
     "shell.execute_reply": "2024-10-29T06:24:36.533455Z"
    },
    "papermill": {
     "duration": 38822.857619,
     "end_time": "2024-10-29T06:24:36.536496",
     "exception": false,
     "start_time": "2024-10-28T19:37:33.678877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for c3\n",
      "Initializing model c3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74809382d2554a5590443e0291470bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57df8a0ed1ea4a0789213ceba10d6585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]: 100%|██████████| 342/342 [14:13<00:00,  2.49s/batch, loss=0.496]\n",
      "Epoch 1/40 [Validation]: 100%|██████████| 86/86 [02:38<00:00,  1.84s/batch, loss=0.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "Training Loss: 0.7091\n",
      "Validation Loss: 0.6083\n",
      "Attribute 1 - Train Acc: 60.36%, Val Acc: 69.89%\n",
      "Attribute 2 - Train Acc: 60.40%, Val Acc: 64.76%\n",
      "Attribute 3 - Train Acc: 59.43%, Val Acc: 64.76%\n",
      "Attribute 4 - Train Acc: 88.24%, Val Acc: 87.69%\n",
      "Attribute 5 - Train Acc: 65.09%, Val Acc: 68.94%\n",
      "Attribute 6 - Train Acc: 61.48%, Val Acc: 62.71%\n",
      "Attribute 7 - Train Acc: 61.19%, Val Acc: 63.81%\n",
      "Attribute 8 - Train Acc: 88.35%, Val Acc: 93.41%\n",
      "Attribute 9 - Train Acc: 95.55%, Val Acc: 97.80%\n",
      "Overall Train Accuracy: 10.94%\n",
      "Overall Validation Accuracy: 13.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 [Training]: 100%|██████████| 342/342 [13:45<00:00,  2.41s/batch, loss=0.277]\n",
      "Epoch 2/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.62s/batch, loss=0.548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "Training Loss: 0.5698\n",
      "Validation Loss: 0.5659\n",
      "Attribute 1 - Train Acc: 75.55%, Val Acc: 75.09%\n",
      "Attribute 2 - Train Acc: 67.09%, Val Acc: 61.32%\n",
      "Attribute 3 - Train Acc: 66.01%, Val Acc: 68.28%\n",
      "Attribute 4 - Train Acc: 89.39%, Val Acc: 90.04%\n",
      "Attribute 5 - Train Acc: 71.23%, Val Acc: 70.18%\n",
      "Attribute 6 - Train Acc: 66.90%, Val Acc: 67.40%\n",
      "Attribute 7 - Train Acc: 67.34%, Val Acc: 64.25%\n",
      "Attribute 8 - Train Acc: 93.64%, Val Acc: 93.85%\n",
      "Attribute 9 - Train Acc: 97.29%, Val Acc: 97.95%\n",
      "Overall Train Accuracy: 19.04%\n",
      "Overall Validation Accuracy: 18.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 [Training]: 100%|██████████| 342/342 [13:43<00:00,  2.41s/batch, loss=0.887]\n",
      "Epoch 3/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40\n",
      "Training Loss: 0.5179\n",
      "Validation Loss: 0.5282\n",
      "Attribute 1 - Train Acc: 79.57%, Val Acc: 77.22%\n",
      "Attribute 2 - Train Acc: 69.49%, Val Acc: 69.08%\n",
      "Attribute 3 - Train Acc: 69.14%, Val Acc: 67.91%\n",
      "Attribute 4 - Train Acc: 90.60%, Val Acc: 89.01%\n",
      "Attribute 5 - Train Acc: 72.57%, Val Acc: 74.14%\n",
      "Attribute 6 - Train Acc: 69.73%, Val Acc: 71.65%\n",
      "Attribute 7 - Train Acc: 70.08%, Val Acc: 69.74%\n",
      "Attribute 8 - Train Acc: 94.81%, Val Acc: 93.92%\n",
      "Attribute 9 - Train Acc: 97.53%, Val Acc: 98.02%\n",
      "Overall Train Accuracy: 23.25%\n",
      "Overall Validation Accuracy: 23.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 [Training]: 100%|██████████| 342/342 [13:45<00:00,  2.41s/batch, loss=0.321]\n",
      "Epoch 4/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40\n",
      "Training Loss: 0.4819\n",
      "Validation Loss: 0.5042\n",
      "Attribute 1 - Train Acc: 82.43%, Val Acc: 78.90%\n",
      "Attribute 2 - Train Acc: 70.90%, Val Acc: 70.92%\n",
      "Attribute 3 - Train Acc: 69.65%, Val Acc: 69.01%\n",
      "Attribute 4 - Train Acc: 90.95%, Val Acc: 89.45%\n",
      "Attribute 5 - Train Acc: 73.98%, Val Acc: 73.26%\n",
      "Attribute 6 - Train Acc: 70.92%, Val Acc: 70.84%\n",
      "Attribute 7 - Train Acc: 71.16%, Val Acc: 70.18%\n",
      "Attribute 8 - Train Acc: 95.13%, Val Acc: 94.58%\n",
      "Attribute 9 - Train Acc: 97.93%, Val Acc: 97.88%\n",
      "Overall Train Accuracy: 25.33%\n",
      "Overall Validation Accuracy: 24.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 [Training]: 100%|██████████| 342/342 [13:46<00:00,  2.42s/batch, loss=0.438]\n",
      "Epoch 5/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40\n",
      "Training Loss: 0.4532\n",
      "Validation Loss: 0.5114\n",
      "Attribute 1 - Train Acc: 84.04%, Val Acc: 79.27%\n",
      "Attribute 2 - Train Acc: 71.96%, Val Acc: 67.55%\n",
      "Attribute 3 - Train Acc: 71.30%, Val Acc: 68.57%\n",
      "Attribute 4 - Train Acc: 91.61%, Val Acc: 89.74%\n",
      "Attribute 5 - Train Acc: 73.91%, Val Acc: 72.75%\n",
      "Attribute 6 - Train Acc: 72.05%, Val Acc: 70.18%\n",
      "Attribute 7 - Train Acc: 72.16%, Val Acc: 67.69%\n",
      "Attribute 8 - Train Acc: 95.55%, Val Acc: 94.73%\n",
      "Attribute 9 - Train Acc: 98.15%, Val Acc: 98.10%\n",
      "Overall Train Accuracy: 27.74%\n",
      "Overall Validation Accuracy: 21.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 [Training]: 100%|██████████| 342/342 [13:47<00:00,  2.42s/batch, loss=0.908]\n",
      "Epoch 6/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "Training Loss: 0.4299\n",
      "Validation Loss: 0.4959\n",
      "Attribute 1 - Train Acc: 85.71%, Val Acc: 80.29%\n",
      "Attribute 2 - Train Acc: 73.14%, Val Acc: 70.92%\n",
      "Attribute 3 - Train Acc: 72.16%, Val Acc: 69.82%\n",
      "Attribute 4 - Train Acc: 92.05%, Val Acc: 89.23%\n",
      "Attribute 5 - Train Acc: 74.82%, Val Acc: 73.99%\n",
      "Attribute 6 - Train Acc: 72.84%, Val Acc: 71.58%\n",
      "Attribute 7 - Train Acc: 73.41%, Val Acc: 69.67%\n",
      "Attribute 8 - Train Acc: 96.01%, Val Acc: 95.97%\n",
      "Attribute 9 - Train Acc: 98.09%, Val Acc: 97.80%\n",
      "Overall Train Accuracy: 29.23%\n",
      "Overall Validation Accuracy: 25.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 [Training]: 100%|██████████| 342/342 [13:42<00:00,  2.40s/batch, loss=0.545]\n",
      "Epoch 7/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40\n",
      "Training Loss: 0.4083\n",
      "Validation Loss: 0.4864\n",
      "Attribute 1 - Train Acc: 87.48%, Val Acc: 82.71%\n",
      "Attribute 2 - Train Acc: 73.17%, Val Acc: 68.94%\n",
      "Attribute 3 - Train Acc: 73.41%, Val Acc: 70.04%\n",
      "Attribute 4 - Train Acc: 92.82%, Val Acc: 89.45%\n",
      "Attribute 5 - Train Acc: 75.55%, Val Acc: 73.26%\n",
      "Attribute 6 - Train Acc: 73.81%, Val Acc: 70.99%\n",
      "Attribute 7 - Train Acc: 74.00%, Val Acc: 69.74%\n",
      "Attribute 8 - Train Acc: 96.48%, Val Acc: 95.60%\n",
      "Attribute 9 - Train Acc: 98.39%, Val Acc: 98.02%\n",
      "Overall Train Accuracy: 31.23%\n",
      "Overall Validation Accuracy: 24.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 [Training]: 100%|██████████| 342/342 [13:42<00:00,  2.41s/batch, loss=0.0466]\n",
      "Epoch 8/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "Training Loss: 0.3913\n",
      "Validation Loss: 0.5078\n",
      "Attribute 1 - Train Acc: 88.03%, Val Acc: 82.42%\n",
      "Attribute 2 - Train Acc: 74.16%, Val Acc: 69.08%\n",
      "Attribute 3 - Train Acc: 74.00%, Val Acc: 69.16%\n",
      "Attribute 4 - Train Acc: 93.26%, Val Acc: 90.11%\n",
      "Attribute 5 - Train Acc: 75.37%, Val Acc: 72.89%\n",
      "Attribute 6 - Train Acc: 74.20%, Val Acc: 69.82%\n",
      "Attribute 7 - Train Acc: 74.11%, Val Acc: 69.16%\n",
      "Attribute 8 - Train Acc: 96.44%, Val Acc: 95.60%\n",
      "Attribute 9 - Train Acc: 98.39%, Val Acc: 98.32%\n",
      "Overall Train Accuracy: 32.23%\n",
      "Overall Validation Accuracy: 25.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 [Training]: 100%|██████████| 342/342 [13:40<00:00,  2.40s/batch, loss=0.319]\n",
      "Epoch 9/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40\n",
      "Training Loss: 0.3768\n",
      "Validation Loss: 0.4958\n",
      "Attribute 1 - Train Acc: 89.83%, Val Acc: 83.59%\n",
      "Attribute 2 - Train Acc: 74.93%, Val Acc: 70.40%\n",
      "Attribute 3 - Train Acc: 74.47%, Val Acc: 70.18%\n",
      "Attribute 4 - Train Acc: 93.93%, Val Acc: 89.45%\n",
      "Attribute 5 - Train Acc: 75.74%, Val Acc: 72.89%\n",
      "Attribute 6 - Train Acc: 74.22%, Val Acc: 71.21%\n",
      "Attribute 7 - Train Acc: 75.28%, Val Acc: 69.52%\n",
      "Attribute 8 - Train Acc: 96.74%, Val Acc: 93.99%\n",
      "Attribute 9 - Train Acc: 98.46%, Val Acc: 94.87%\n",
      "Overall Train Accuracy: 33.97%\n",
      "Overall Validation Accuracy: 25.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 [Training]: 100%|██████████| 342/342 [13:41<00:00,  2.40s/batch, loss=0.798]\n",
      "Epoch 10/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.62s/batch, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "Training Loss: 0.3599\n",
      "Validation Loss: 0.5036\n",
      "Attribute 1 - Train Acc: 90.82%, Val Acc: 83.30%\n",
      "Attribute 2 - Train Acc: 75.66%, Val Acc: 70.48%\n",
      "Attribute 3 - Train Acc: 75.48%, Val Acc: 68.06%\n",
      "Attribute 4 - Train Acc: 93.92%, Val Acc: 89.82%\n",
      "Attribute 5 - Train Acc: 76.98%, Val Acc: 72.38%\n",
      "Attribute 6 - Train Acc: 75.81%, Val Acc: 71.94%\n",
      "Attribute 7 - Train Acc: 76.31%, Val Acc: 69.96%\n",
      "Attribute 8 - Train Acc: 96.83%, Val Acc: 95.68%\n",
      "Attribute 9 - Train Acc: 98.50%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 35.61%\n",
      "Overall Validation Accuracy: 25.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 [Training]: 100%|██████████| 342/342 [13:49<00:00,  2.43s/batch, loss=0.2]\n",
      "Epoch 11/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.63s/batch, loss=0.297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "Training Loss: 0.3448\n",
      "Validation Loss: 0.4926\n",
      "Attribute 1 - Train Acc: 91.26%, Val Acc: 83.44%\n",
      "Attribute 2 - Train Acc: 76.09%, Val Acc: 68.79%\n",
      "Attribute 3 - Train Acc: 76.51%, Val Acc: 69.23%\n",
      "Attribute 4 - Train Acc: 94.30%, Val Acc: 90.18%\n",
      "Attribute 5 - Train Acc: 77.37%, Val Acc: 73.63%\n",
      "Attribute 6 - Train Acc: 76.54%, Val Acc: 70.40%\n",
      "Attribute 7 - Train Acc: 76.58%, Val Acc: 68.86%\n",
      "Attribute 8 - Train Acc: 97.10%, Val Acc: 95.68%\n",
      "Attribute 9 - Train Acc: 98.77%, Val Acc: 97.36%\n",
      "Overall Train Accuracy: 36.52%\n",
      "Overall Validation Accuracy: 26.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 [Training]: 100%|██████████| 342/342 [13:42<00:00,  2.40s/batch, loss=0.35]\n",
      "Epoch 12/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.62s/batch, loss=0.561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      "Training Loss: 0.3300\n",
      "Validation Loss: 0.5067\n",
      "Attribute 1 - Train Acc: 92.52%, Val Acc: 84.40%\n",
      "Attribute 2 - Train Acc: 76.47%, Val Acc: 69.01%\n",
      "Attribute 3 - Train Acc: 77.20%, Val Acc: 69.45%\n",
      "Attribute 4 - Train Acc: 94.74%, Val Acc: 89.38%\n",
      "Attribute 5 - Train Acc: 78.17%, Val Acc: 72.38%\n",
      "Attribute 6 - Train Acc: 76.69%, Val Acc: 71.06%\n",
      "Attribute 7 - Train Acc: 77.31%, Val Acc: 70.26%\n",
      "Attribute 8 - Train Acc: 97.10%, Val Acc: 96.04%\n",
      "Attribute 9 - Train Acc: 98.68%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 38.72%\n",
      "Overall Validation Accuracy: 25.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40 [Training]: 100%|██████████| 342/342 [13:46<00:00,  2.42s/batch, loss=0.0118]\n",
      "Epoch 13/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40\n",
      "Training Loss: 0.3151\n",
      "Validation Loss: 0.5342\n",
      "Attribute 1 - Train Acc: 93.82%, Val Acc: 83.66%\n",
      "Attribute 2 - Train Acc: 77.79%, Val Acc: 69.52%\n",
      "Attribute 3 - Train Acc: 77.99%, Val Acc: 68.06%\n",
      "Attribute 4 - Train Acc: 95.03%, Val Acc: 89.67%\n",
      "Attribute 5 - Train Acc: 78.63%, Val Acc: 71.87%\n",
      "Attribute 6 - Train Acc: 77.55%, Val Acc: 70.11%\n",
      "Attribute 7 - Train Acc: 77.41%, Val Acc: 69.96%\n",
      "Attribute 8 - Train Acc: 97.54%, Val Acc: 95.97%\n",
      "Attribute 9 - Train Acc: 98.92%, Val Acc: 97.95%\n",
      "Overall Train Accuracy: 39.73%\n",
      "Overall Validation Accuracy: 26.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40 [Training]: 100%|██████████| 342/342 [13:45<00:00,  2.41s/batch, loss=0.698]\n",
      "Epoch 14/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "Training Loss: 0.3069\n",
      "Validation Loss: 0.5556\n",
      "Attribute 1 - Train Acc: 94.32%, Val Acc: 83.81%\n",
      "Attribute 2 - Train Acc: 78.39%, Val Acc: 68.79%\n",
      "Attribute 3 - Train Acc: 78.08%, Val Acc: 66.23%\n",
      "Attribute 4 - Train Acc: 95.51%, Val Acc: 89.45%\n",
      "Attribute 5 - Train Acc: 79.42%, Val Acc: 72.53%\n",
      "Attribute 6 - Train Acc: 77.22%, Val Acc: 68.72%\n",
      "Attribute 7 - Train Acc: 77.79%, Val Acc: 67.18%\n",
      "Attribute 8 - Train Acc: 97.67%, Val Acc: 95.90%\n",
      "Attribute 9 - Train Acc: 99.03%, Val Acc: 97.73%\n",
      "Overall Train Accuracy: 40.99%\n",
      "Overall Validation Accuracy: 25.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40 [Training]: 100%|██████████| 342/342 [13:42<00:00,  2.40s/batch, loss=0.559]\n",
      "Epoch 15/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40\n",
      "Training Loss: 0.2952\n",
      "Validation Loss: 0.5679\n",
      "Attribute 1 - Train Acc: 94.36%, Val Acc: 84.47%\n",
      "Attribute 2 - Train Acc: 78.41%, Val Acc: 69.01%\n",
      "Attribute 3 - Train Acc: 79.09%, Val Acc: 66.37%\n",
      "Attribute 4 - Train Acc: 95.93%, Val Acc: 86.59%\n",
      "Attribute 5 - Train Acc: 79.13%, Val Acc: 70.92%\n",
      "Attribute 6 - Train Acc: 77.92%, Val Acc: 69.23%\n",
      "Attribute 7 - Train Acc: 78.21%, Val Acc: 68.50%\n",
      "Attribute 8 - Train Acc: 97.71%, Val Acc: 95.75%\n",
      "Attribute 9 - Train Acc: 98.97%, Val Acc: 98.10%\n",
      "Overall Train Accuracy: 41.71%\n",
      "Overall Validation Accuracy: 27.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40 [Training]: 100%|██████████| 342/342 [13:42<00:00,  2.41s/batch, loss=0.0881]\n",
      "Epoch 16/40 [Validation]: 100%|██████████| 86/86 [02:16<00:00,  1.59s/batch, loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40\n",
      "Training Loss: 0.2856\n",
      "Validation Loss: 0.5753\n",
      "Attribute 1 - Train Acc: 95.02%, Val Acc: 84.10%\n",
      "Attribute 2 - Train Acc: 78.69%, Val Acc: 67.11%\n",
      "Attribute 3 - Train Acc: 79.29%, Val Acc: 66.81%\n",
      "Attribute 4 - Train Acc: 95.73%, Val Acc: 88.94%\n",
      "Attribute 5 - Train Acc: 79.92%, Val Acc: 69.96%\n",
      "Attribute 6 - Train Acc: 77.74%, Val Acc: 68.72%\n",
      "Attribute 7 - Train Acc: 78.83%, Val Acc: 66.37%\n",
      "Attribute 8 - Train Acc: 98.02%, Val Acc: 95.68%\n",
      "Attribute 9 - Train Acc: 99.12%, Val Acc: 96.85%\n",
      "Overall Train Accuracy: 42.31%\n",
      "Overall Validation Accuracy: 25.35%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40 [Training]: 100%|██████████| 342/342 [13:46<00:00,  2.42s/batch, loss=0.0251]\n",
      "Epoch 17/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "Training Loss: 0.2754\n",
      "Validation Loss: 0.5873\n",
      "Attribute 1 - Train Acc: 95.58%, Val Acc: 85.20%\n",
      "Attribute 2 - Train Acc: 79.51%, Val Acc: 68.21%\n",
      "Attribute 3 - Train Acc: 79.79%, Val Acc: 64.91%\n",
      "Attribute 4 - Train Acc: 96.37%, Val Acc: 88.72%\n",
      "Attribute 5 - Train Acc: 80.26%, Val Acc: 70.84%\n",
      "Attribute 6 - Train Acc: 78.36%, Val Acc: 67.69%\n",
      "Attribute 7 - Train Acc: 78.96%, Val Acc: 67.11%\n",
      "Attribute 8 - Train Acc: 98.15%, Val Acc: 96.19%\n",
      "Attribute 9 - Train Acc: 98.96%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 43.80%\n",
      "Overall Validation Accuracy: 26.81%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40 [Training]: 100%|██████████| 342/342 [13:45<00:00,  2.41s/batch, loss=0.0101]\n",
      "Epoch 18/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.63s/batch, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40\n",
      "Training Loss: 0.2656\n",
      "Validation Loss: 0.6082\n",
      "Attribute 1 - Train Acc: 95.80%, Val Acc: 84.91%\n",
      "Attribute 2 - Train Acc: 80.41%, Val Acc: 67.77%\n",
      "Attribute 3 - Train Acc: 80.01%, Val Acc: 65.42%\n",
      "Attribute 4 - Train Acc: 96.52%, Val Acc: 89.16%\n",
      "Attribute 5 - Train Acc: 80.61%, Val Acc: 72.09%\n",
      "Attribute 6 - Train Acc: 79.27%, Val Acc: 69.74%\n",
      "Attribute 7 - Train Acc: 79.60%, Val Acc: 68.64%\n",
      "Attribute 8 - Train Acc: 97.91%, Val Acc: 96.12%\n",
      "Attribute 9 - Train Acc: 99.29%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 44.64%\n",
      "Overall Validation Accuracy: 26.52%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40 [Training]: 100%|██████████| 342/342 [13:43<00:00,  2.41s/batch, loss=0.0136]\n",
      "Epoch 19/40 [Validation]: 100%|██████████| 86/86 [02:16<00:00,  1.59s/batch, loss=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "Training Loss: 0.2340\n",
      "Validation Loss: 0.6255\n",
      "Attribute 1 - Train Acc: 96.90%, Val Acc: 86.67%\n",
      "Attribute 2 - Train Acc: 81.95%, Val Acc: 66.81%\n",
      "Attribute 3 - Train Acc: 81.84%, Val Acc: 64.32%\n",
      "Attribute 4 - Train Acc: 97.27%, Val Acc: 89.82%\n",
      "Attribute 5 - Train Acc: 82.54%, Val Acc: 70.55%\n",
      "Attribute 6 - Train Acc: 80.69%, Val Acc: 68.13%\n",
      "Attribute 7 - Train Acc: 80.80%, Val Acc: 66.67%\n",
      "Attribute 8 - Train Acc: 98.53%, Val Acc: 96.12%\n",
      "Attribute 9 - Train Acc: 99.41%, Val Acc: 97.88%\n",
      "Overall Train Accuracy: 48.91%\n",
      "Overall Validation Accuracy: 26.67%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40 [Training]: 100%|██████████| 342/342 [13:44<00:00,  2.41s/batch, loss=0.577]\n",
      "Epoch 20/40 [Validation]: 100%|██████████| 86/86 [02:16<00:00,  1.58s/batch, loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "Training Loss: 0.2187\n",
      "Validation Loss: 0.6657\n",
      "Attribute 1 - Train Acc: 97.71%, Val Acc: 86.52%\n",
      "Attribute 2 - Train Acc: 82.10%, Val Acc: 66.45%\n",
      "Attribute 3 - Train Acc: 82.83%, Val Acc: 64.54%\n",
      "Attribute 4 - Train Acc: 97.69%, Val Acc: 88.86%\n",
      "Attribute 5 - Train Acc: 83.10%, Val Acc: 70.04%\n",
      "Attribute 6 - Train Acc: 80.91%, Val Acc: 67.18%\n",
      "Attribute 7 - Train Acc: 81.02%, Val Acc: 66.37%\n",
      "Attribute 8 - Train Acc: 98.74%, Val Acc: 95.68%\n",
      "Attribute 9 - Train Acc: 99.43%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 50.71%\n",
      "Overall Validation Accuracy: 26.74%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/40 [Training]: 100%|██████████| 342/342 [13:37<00:00,  2.39s/batch, loss=0.172]\n",
      "Epoch 21/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "Training Loss: 0.2080\n",
      "Validation Loss: 0.6794\n",
      "Attribute 1 - Train Acc: 97.67%, Val Acc: 86.37%\n",
      "Attribute 2 - Train Acc: 82.72%, Val Acc: 66.15%\n",
      "Attribute 3 - Train Acc: 82.52%, Val Acc: 64.32%\n",
      "Attribute 4 - Train Acc: 97.80%, Val Acc: 89.16%\n",
      "Attribute 5 - Train Acc: 83.47%, Val Acc: 67.69%\n",
      "Attribute 6 - Train Acc: 81.42%, Val Acc: 66.81%\n",
      "Attribute 7 - Train Acc: 81.44%, Val Acc: 65.27%\n",
      "Attribute 8 - Train Acc: 98.77%, Val Acc: 96.19%\n",
      "Attribute 9 - Train Acc: 99.60%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 52.10%\n",
      "Overall Validation Accuracy: 25.64%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/40 [Training]: 100%|██████████| 342/342 [13:40<00:00,  2.40s/batch, loss=0.544]\n",
      "Epoch 22/40 [Validation]: 100%|██████████| 86/86 [02:16<00:00,  1.59s/batch, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "Training Loss: 0.1918\n",
      "Validation Loss: 0.7443\n",
      "Attribute 1 - Train Acc: 98.09%, Val Acc: 86.67%\n",
      "Attribute 2 - Train Acc: 83.64%, Val Acc: 64.32%\n",
      "Attribute 3 - Train Acc: 83.73%, Val Acc: 63.15%\n",
      "Attribute 4 - Train Acc: 98.02%, Val Acc: 89.01%\n",
      "Attribute 5 - Train Acc: 84.55%, Val Acc: 67.62%\n",
      "Attribute 6 - Train Acc: 82.32%, Val Acc: 65.64%\n",
      "Attribute 7 - Train Acc: 82.65%, Val Acc: 65.20%\n",
      "Attribute 8 - Train Acc: 99.08%, Val Acc: 96.04%\n",
      "Attribute 9 - Train Acc: 99.51%, Val Acc: 98.32%\n",
      "Overall Train Accuracy: 55.21%\n",
      "Overall Validation Accuracy: 26.59%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/40 [Training]: 100%|██████████| 342/342 [13:38<00:00,  2.39s/batch, loss=0.314]\n",
      "Epoch 23/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "Training Loss: 0.1833\n",
      "Validation Loss: 0.7859\n",
      "Attribute 1 - Train Acc: 98.13%, Val Acc: 86.96%\n",
      "Attribute 2 - Train Acc: 84.17%, Val Acc: 63.81%\n",
      "Attribute 3 - Train Acc: 84.50%, Val Acc: 62.42%\n",
      "Attribute 4 - Train Acc: 97.89%, Val Acc: 88.79%\n",
      "Attribute 5 - Train Acc: 84.59%, Val Acc: 66.15%\n",
      "Attribute 6 - Train Acc: 82.41%, Val Acc: 64.40%\n",
      "Attribute 7 - Train Acc: 82.81%, Val Acc: 65.13%\n",
      "Attribute 8 - Train Acc: 98.85%, Val Acc: 95.90%\n",
      "Attribute 9 - Train Acc: 99.62%, Val Acc: 98.39%\n",
      "Overall Train Accuracy: 55.93%\n",
      "Overall Validation Accuracy: 25.27%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/40 [Training]: 100%|██████████| 342/342 [13:36<00:00,  2.39s/batch, loss=0.0147]\n",
      "Epoch 24/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40\n",
      "Training Loss: 0.1772\n",
      "Validation Loss: 0.8068\n",
      "Attribute 1 - Train Acc: 98.48%, Val Acc: 87.84%\n",
      "Attribute 2 - Train Acc: 84.31%, Val Acc: 64.69%\n",
      "Attribute 3 - Train Acc: 85.07%, Val Acc: 61.47%\n",
      "Attribute 4 - Train Acc: 97.91%, Val Acc: 88.64%\n",
      "Attribute 5 - Train Acc: 84.83%, Val Acc: 67.55%\n",
      "Attribute 6 - Train Acc: 83.16%, Val Acc: 64.76%\n",
      "Attribute 7 - Train Acc: 82.92%, Val Acc: 64.47%\n",
      "Attribute 8 - Train Acc: 98.86%, Val Acc: 95.90%\n",
      "Attribute 9 - Train Acc: 99.62%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 57.14%\n",
      "Overall Validation Accuracy: 25.27%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/40 [Training]: 100%|██████████| 342/342 [13:43<00:00,  2.41s/batch, loss=0.465]\n",
      "Epoch 25/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40\n",
      "Training Loss: 0.1708\n",
      "Validation Loss: 0.8334\n",
      "Attribute 1 - Train Acc: 98.50%, Val Acc: 87.47%\n",
      "Attribute 2 - Train Acc: 84.85%, Val Acc: 62.56%\n",
      "Attribute 3 - Train Acc: 84.83%, Val Acc: 61.54%\n",
      "Attribute 4 - Train Acc: 98.04%, Val Acc: 89.38%\n",
      "Attribute 5 - Train Acc: 85.38%, Val Acc: 65.49%\n",
      "Attribute 6 - Train Acc: 83.76%, Val Acc: 64.18%\n",
      "Attribute 7 - Train Acc: 83.87%, Val Acc: 63.37%\n",
      "Attribute 8 - Train Acc: 99.07%, Val Acc: 96.04%\n",
      "Attribute 9 - Train Acc: 99.62%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 58.22%\n",
      "Overall Validation Accuracy: 24.84%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/40 [Training]: 100%|██████████| 342/342 [13:40<00:00,  2.40s/batch, loss=0.00784]\n",
      "Epoch 26/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.62s/batch, loss=0.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "Training Loss: 0.1658\n",
      "Validation Loss: 0.8469\n",
      "Attribute 1 - Train Acc: 98.44%, Val Acc: 87.18%\n",
      "Attribute 2 - Train Acc: 85.07%, Val Acc: 63.66%\n",
      "Attribute 3 - Train Acc: 84.85%, Val Acc: 61.10%\n",
      "Attribute 4 - Train Acc: 97.97%, Val Acc: 89.30%\n",
      "Attribute 5 - Train Acc: 85.85%, Val Acc: 67.69%\n",
      "Attribute 6 - Train Acc: 83.62%, Val Acc: 63.88%\n",
      "Attribute 7 - Train Acc: 84.41%, Val Acc: 63.74%\n",
      "Attribute 8 - Train Acc: 99.07%, Val Acc: 96.34%\n",
      "Attribute 9 - Train Acc: 99.65%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 59.03%\n",
      "Overall Validation Accuracy: 24.76%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/40 [Training]: 100%|██████████| 342/342 [13:39<00:00,  2.40s/batch, loss=0.068]\n",
      "Epoch 27/40 [Validation]: 100%|██████████| 86/86 [02:16<00:00,  1.59s/batch, loss=0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40\n",
      "Training Loss: 0.1612\n",
      "Validation Loss: 0.8701\n",
      "Attribute 1 - Train Acc: 98.46%, Val Acc: 86.23%\n",
      "Attribute 2 - Train Acc: 85.08%, Val Acc: 62.12%\n",
      "Attribute 3 - Train Acc: 85.72%, Val Acc: 60.95%\n",
      "Attribute 4 - Train Acc: 98.13%, Val Acc: 88.42%\n",
      "Attribute 5 - Train Acc: 85.52%, Val Acc: 66.89%\n",
      "Attribute 6 - Train Acc: 84.11%, Val Acc: 63.66%\n",
      "Attribute 7 - Train Acc: 84.55%, Val Acc: 64.18%\n",
      "Attribute 8 - Train Acc: 99.18%, Val Acc: 96.12%\n",
      "Attribute 9 - Train Acc: 99.63%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 59.28%\n",
      "Overall Validation Accuracy: 24.18%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/40 [Training]: 100%|██████████| 342/342 [13:43<00:00,  2.41s/batch, loss=0.0544]\n",
      "Epoch 28/40 [Validation]: 100%|██████████| 86/86 [02:17<00:00,  1.60s/batch, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      "Training Loss: 0.1584\n",
      "Validation Loss: 0.8953\n",
      "Attribute 1 - Train Acc: 98.53%, Val Acc: 86.96%\n",
      "Attribute 2 - Train Acc: 85.47%, Val Acc: 61.98%\n",
      "Attribute 3 - Train Acc: 86.05%, Val Acc: 60.73%\n",
      "Attribute 4 - Train Acc: 98.22%, Val Acc: 88.86%\n",
      "Attribute 5 - Train Acc: 86.09%, Val Acc: 66.52%\n",
      "Attribute 6 - Train Acc: 84.17%, Val Acc: 62.86%\n",
      "Attribute 7 - Train Acc: 84.83%, Val Acc: 61.76%\n",
      "Attribute 8 - Train Acc: 99.07%, Val Acc: 95.68%\n",
      "Attribute 9 - Train Acc: 99.74%, Val Acc: 98.32%\n",
      "Overall Train Accuracy: 60.66%\n",
      "Overall Validation Accuracy: 24.18%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/40 [Training]: 100%|██████████| 342/342 [13:44<00:00,  2.41s/batch, loss=0.881]\n",
      "Epoch 29/40 [Validation]: 100%|██████████| 86/86 [02:19<00:00,  1.62s/batch, loss=0.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "Training Loss: 0.1593\n",
      "Validation Loss: 0.8982\n",
      "Attribute 1 - Train Acc: 98.59%, Val Acc: 87.33%\n",
      "Attribute 2 - Train Acc: 85.63%, Val Acc: 62.27%\n",
      "Attribute 3 - Train Acc: 85.89%, Val Acc: 60.00%\n",
      "Attribute 4 - Train Acc: 98.22%, Val Acc: 89.23%\n",
      "Attribute 5 - Train Acc: 86.26%, Val Acc: 66.23%\n",
      "Attribute 6 - Train Acc: 83.73%, Val Acc: 62.20%\n",
      "Attribute 7 - Train Acc: 84.57%, Val Acc: 61.39%\n",
      "Attribute 8 - Train Acc: 99.14%, Val Acc: 96.41%\n",
      "Attribute 9 - Train Acc: 99.67%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 60.49%\n",
      "Overall Validation Accuracy: 23.88%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/40 [Training]: 100%|██████████| 342/342 [13:46<00:00,  2.42s/batch, loss=0.00992]\n",
      "Epoch 30/40 [Validation]: 100%|██████████| 86/86 [02:20<00:00,  1.64s/batch, loss=0.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "Training Loss: 0.1536\n",
      "Validation Loss: 0.9217\n",
      "Attribute 1 - Train Acc: 98.61%, Val Acc: 86.96%\n",
      "Attribute 2 - Train Acc: 85.74%, Val Acc: 61.68%\n",
      "Attribute 3 - Train Acc: 86.27%, Val Acc: 60.22%\n",
      "Attribute 4 - Train Acc: 98.24%, Val Acc: 88.57%\n",
      "Attribute 5 - Train Acc: 86.49%, Val Acc: 65.42%\n",
      "Attribute 6 - Train Acc: 84.52%, Val Acc: 62.78%\n",
      "Attribute 7 - Train Acc: 84.63%, Val Acc: 62.49%\n",
      "Attribute 8 - Train Acc: 99.12%, Val Acc: 95.75%\n",
      "Attribute 9 - Train Acc: 99.71%, Val Acc: 98.02%\n",
      "Overall Train Accuracy: 61.02%\n",
      "Overall Validation Accuracy: 23.74%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/40 [Training]: 100%|██████████| 342/342 [13:47<00:00,  2.42s/batch, loss=0.404]\n",
      "Epoch 31/40 [Validation]: 100%|██████████| 86/86 [02:18<00:00,  1.61s/batch, loss=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "Training Loss: 0.1537\n",
      "Validation Loss: 0.9316\n",
      "Attribute 1 - Train Acc: 98.63%, Val Acc: 87.18%\n",
      "Attribute 2 - Train Acc: 85.45%, Val Acc: 62.12%\n",
      "Attribute 3 - Train Acc: 86.46%, Val Acc: 60.07%\n",
      "Attribute 4 - Train Acc: 98.39%, Val Acc: 88.57%\n",
      "Attribute 5 - Train Acc: 86.48%, Val Acc: 66.45%\n",
      "Attribute 6 - Train Acc: 84.81%, Val Acc: 62.93%\n",
      "Attribute 7 - Train Acc: 85.47%, Val Acc: 62.78%\n",
      "Attribute 8 - Train Acc: 99.19%, Val Acc: 95.90%\n",
      "Attribute 9 - Train Acc: 99.67%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 61.57%\n",
      "Overall Validation Accuracy: 24.84%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/40 [Training]: 100%|██████████| 342/342 [13:50<00:00,  2.43s/batch, loss=0.0126]\n",
      "Epoch 32/40 [Validation]: 100%|██████████| 86/86 [02:28<00:00,  1.73s/batch, loss=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "Training Loss: 0.1497\n",
      "Validation Loss: 0.9352\n",
      "Attribute 1 - Train Acc: 98.74%, Val Acc: 87.91%\n",
      "Attribute 2 - Train Acc: 85.65%, Val Acc: 62.05%\n",
      "Attribute 3 - Train Acc: 86.60%, Val Acc: 59.34%\n",
      "Attribute 4 - Train Acc: 98.28%, Val Acc: 89.01%\n",
      "Attribute 5 - Train Acc: 86.88%, Val Acc: 65.20%\n",
      "Attribute 6 - Train Acc: 85.23%, Val Acc: 63.00%\n",
      "Attribute 7 - Train Acc: 85.85%, Val Acc: 61.54%\n",
      "Attribute 8 - Train Acc: 99.08%, Val Acc: 96.19%\n",
      "Attribute 9 - Train Acc: 99.67%, Val Acc: 98.02%\n",
      "Overall Train Accuracy: 61.98%\n",
      "Overall Validation Accuracy: 24.25%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/40 [Training]: 100%|██████████| 342/342 [13:47<00:00,  2.42s/batch, loss=0.0129]\n",
      "Epoch 33/40 [Validation]: 100%|██████████| 86/86 [02:21<00:00,  1.65s/batch, loss=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "Training Loss: 0.1498\n",
      "Validation Loss: 0.9402\n",
      "Attribute 1 - Train Acc: 98.74%, Val Acc: 87.77%\n",
      "Attribute 2 - Train Acc: 85.82%, Val Acc: 62.20%\n",
      "Attribute 3 - Train Acc: 86.48%, Val Acc: 60.15%\n",
      "Attribute 4 - Train Acc: 98.24%, Val Acc: 88.79%\n",
      "Attribute 5 - Train Acc: 86.81%, Val Acc: 64.98%\n",
      "Attribute 6 - Train Acc: 85.08%, Val Acc: 61.76%\n",
      "Attribute 7 - Train Acc: 85.34%, Val Acc: 61.39%\n",
      "Attribute 8 - Train Acc: 99.25%, Val Acc: 96.04%\n",
      "Attribute 9 - Train Acc: 99.78%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 61.70%\n",
      "Overall Validation Accuracy: 24.62%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/40 [Training]: 100%|██████████| 342/342 [13:59<00:00,  2.45s/batch, loss=0.281]\n",
      "Epoch 34/40 [Validation]: 100%|██████████| 86/86 [02:29<00:00,  1.73s/batch, loss=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40\n",
      "Training Loss: 0.1496\n",
      "Validation Loss: 0.9402\n",
      "Attribute 1 - Train Acc: 98.63%, Val Acc: 87.55%\n",
      "Attribute 2 - Train Acc: 85.74%, Val Acc: 62.12%\n",
      "Attribute 3 - Train Acc: 86.75%, Val Acc: 59.12%\n",
      "Attribute 4 - Train Acc: 98.42%, Val Acc: 89.45%\n",
      "Attribute 5 - Train Acc: 87.10%, Val Acc: 66.01%\n",
      "Attribute 6 - Train Acc: 85.30%, Val Acc: 62.34%\n",
      "Attribute 7 - Train Acc: 85.34%, Val Acc: 61.61%\n",
      "Attribute 8 - Train Acc: 99.23%, Val Acc: 95.90%\n",
      "Attribute 9 - Train Acc: 99.69%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 62.29%\n",
      "Overall Validation Accuracy: 24.18%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/40 [Training]: 100%|██████████| 342/342 [14:13<00:00,  2.50s/batch, loss=0.0842]\n",
      "Epoch 35/40 [Validation]: 100%|██████████| 86/86 [02:29<00:00,  1.74s/batch, loss=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40\n",
      "Training Loss: 0.1479\n",
      "Validation Loss: 0.9528\n",
      "Attribute 1 - Train Acc: 98.66%, Val Acc: 87.55%\n",
      "Attribute 2 - Train Acc: 86.07%, Val Acc: 62.27%\n",
      "Attribute 3 - Train Acc: 86.90%, Val Acc: 59.78%\n",
      "Attribute 4 - Train Acc: 98.48%, Val Acc: 88.94%\n",
      "Attribute 5 - Train Acc: 86.86%, Val Acc: 65.42%\n",
      "Attribute 6 - Train Acc: 85.21%, Val Acc: 62.12%\n",
      "Attribute 7 - Train Acc: 85.58%, Val Acc: 61.39%\n",
      "Attribute 8 - Train Acc: 99.30%, Val Acc: 95.68%\n",
      "Attribute 9 - Train Acc: 99.71%, Val Acc: 98.24%\n",
      "Overall Train Accuracy: 62.60%\n",
      "Overall Validation Accuracy: 24.25%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/40 [Training]: 100%|██████████| 342/342 [14:19<00:00,  2.51s/batch, loss=0.00939]\n",
      "Epoch 36/40 [Validation]: 100%|██████████| 86/86 [02:28<00:00,  1.72s/batch, loss=0.746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40\n",
      "Training Loss: 0.1468\n",
      "Validation Loss: 0.9521\n",
      "Attribute 1 - Train Acc: 98.55%, Val Acc: 87.91%\n",
      "Attribute 2 - Train Acc: 86.04%, Val Acc: 61.83%\n",
      "Attribute 3 - Train Acc: 86.49%, Val Acc: 57.80%\n",
      "Attribute 4 - Train Acc: 98.33%, Val Acc: 88.57%\n",
      "Attribute 5 - Train Acc: 87.47%, Val Acc: 65.79%\n",
      "Attribute 6 - Train Acc: 85.03%, Val Acc: 61.98%\n",
      "Attribute 7 - Train Acc: 85.63%, Val Acc: 61.98%\n",
      "Attribute 8 - Train Acc: 99.16%, Val Acc: 95.90%\n",
      "Attribute 9 - Train Acc: 99.71%, Val Acc: 98.10%\n",
      "Overall Train Accuracy: 62.12%\n",
      "Overall Validation Accuracy: 24.25%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/40 [Training]: 100%|██████████| 342/342 [14:12<00:00,  2.49s/batch, loss=0.00868]\n",
      "Epoch 37/40 [Validation]: 100%|██████████| 86/86 [02:28<00:00,  1.73s/batch, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40\n",
      "Training Loss: 0.1468\n",
      "Validation Loss: 0.9570\n",
      "Attribute 1 - Train Acc: 98.61%, Val Acc: 87.77%\n",
      "Attribute 2 - Train Acc: 85.94%, Val Acc: 61.61%\n",
      "Attribute 3 - Train Acc: 87.10%, Val Acc: 59.19%\n",
      "Attribute 4 - Train Acc: 98.42%, Val Acc: 89.01%\n",
      "Attribute 5 - Train Acc: 87.01%, Val Acc: 64.62%\n",
      "Attribute 6 - Train Acc: 85.21%, Val Acc: 61.90%\n",
      "Attribute 7 - Train Acc: 85.82%, Val Acc: 61.47%\n",
      "Attribute 8 - Train Acc: 99.29%, Val Acc: 95.75%\n",
      "Attribute 9 - Train Acc: 99.65%, Val Acc: 98.02%\n",
      "Overall Train Accuracy: 62.56%\n",
      "Overall Validation Accuracy: 23.66%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/40 [Training]: 100%|██████████| 342/342 [14:12<00:00,  2.49s/batch, loss=0.011]\n",
      "Epoch 38/40 [Validation]: 100%|██████████| 86/86 [02:29<00:00,  1.74s/batch, loss=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40\n",
      "Training Loss: 0.1466\n",
      "Validation Loss: 0.9581\n",
      "Attribute 1 - Train Acc: 98.85%, Val Acc: 87.33%\n",
      "Attribute 2 - Train Acc: 86.07%, Val Acc: 61.39%\n",
      "Attribute 3 - Train Acc: 86.88%, Val Acc: 58.83%\n",
      "Attribute 4 - Train Acc: 98.17%, Val Acc: 89.23%\n",
      "Attribute 5 - Train Acc: 87.08%, Val Acc: 64.76%\n",
      "Attribute 6 - Train Acc: 85.69%, Val Acc: 62.12%\n",
      "Attribute 7 - Train Acc: 85.87%, Val Acc: 61.68%\n",
      "Attribute 8 - Train Acc: 99.29%, Val Acc: 96.12%\n",
      "Attribute 9 - Train Acc: 99.69%, Val Acc: 98.32%\n",
      "Overall Train Accuracy: 62.64%\n",
      "Overall Validation Accuracy: 23.81%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/40 [Training]: 100%|██████████| 342/342 [14:08<00:00,  2.48s/batch, loss=0.747]\n",
      "Epoch 39/40 [Validation]: 100%|██████████| 86/86 [02:27<00:00,  1.72s/batch, loss=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40\n",
      "Training Loss: 0.1488\n",
      "Validation Loss: 0.9601\n",
      "Attribute 1 - Train Acc: 98.66%, Val Acc: 86.74%\n",
      "Attribute 2 - Train Acc: 86.07%, Val Acc: 60.73%\n",
      "Attribute 3 - Train Acc: 86.81%, Val Acc: 58.39%\n",
      "Attribute 4 - Train Acc: 98.41%, Val Acc: 89.16%\n",
      "Attribute 5 - Train Acc: 87.08%, Val Acc: 64.84%\n",
      "Attribute 6 - Train Acc: 85.21%, Val Acc: 62.34%\n",
      "Attribute 7 - Train Acc: 86.02%, Val Acc: 62.12%\n",
      "Attribute 8 - Train Acc: 99.19%, Val Acc: 95.75%\n",
      "Attribute 9 - Train Acc: 99.73%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 62.86%\n",
      "Overall Validation Accuracy: 22.86%\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/40 [Training]: 100%|██████████| 342/342 [14:14<00:00,  2.50s/batch, loss=0.00822]\n",
      "Epoch 40/40 [Validation]: 100%|██████████| 86/86 [02:30<00:00,  1.75s/batch, loss=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40\n",
      "Training Loss: 0.1466\n",
      "Validation Loss: 0.9635\n",
      "Attribute 1 - Train Acc: 98.72%, Val Acc: 87.25%\n",
      "Attribute 2 - Train Acc: 86.29%, Val Acc: 61.90%\n",
      "Attribute 3 - Train Acc: 87.26%, Val Acc: 58.97%\n",
      "Attribute 4 - Train Acc: 98.35%, Val Acc: 88.64%\n",
      "Attribute 5 - Train Acc: 87.21%, Val Acc: 65.57%\n",
      "Attribute 6 - Train Acc: 85.03%, Val Acc: 62.20%\n",
      "Attribute 7 - Train Acc: 85.98%, Val Acc: 61.90%\n",
      "Attribute 8 - Train Acc: 99.25%, Val Acc: 95.82%\n",
      "Attribute 9 - Train Acc: 99.73%, Val Acc: 98.17%\n",
      "Overall Train Accuracy: 62.91%\n",
      "Overall Validation Accuracy: 24.25%\n",
      "Early stopping triggered\n",
      "---------------------------------------------\n",
      "number of classes for c3 is [14, 3, 3, 3, 3, 3, 3, 4, 3]\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main(df_c1, df_c2, df_c3, df_c4, df_c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20126b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:24:42.630058Z",
     "iopub.status.busy": "2024-10-29T06:24:42.629607Z",
     "iopub.status.idle": "2024-10-29T06:24:42.649503Z",
     "shell.execute_reply": "2024-10-29T06:24:42.648487Z"
    },
    "papermill": {
     "duration": 3.058774,
     "end_time": "2024-10-29T06:24:42.651793",
     "exception": false,
     "start_time": "2024-10-29T06:24:39.593019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10889</th>\n",
       "      <td>11155</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>11156</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>11157</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>11158</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>11159</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>13610</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>13611</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13346</th>\n",
       "      <td>13612</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>13613</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13348</th>\n",
       "      <td>13614</td>\n",
       "      <td>Kurtis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category\n",
       "10889  11155   Kurtis\n",
       "10890  11156   Kurtis\n",
       "10891  11157   Kurtis\n",
       "10892  11158   Kurtis\n",
       "10893  11159   Kurtis\n",
       "...      ...      ...\n",
       "13344  13610   Kurtis\n",
       "13345  13611   Kurtis\n",
       "13346  13612   Kurtis\n",
       "13347  13613   Kurtis\n",
       "13348  13614   Kurtis\n",
       "\n",
       "[2460 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_c3 = df_test[df_test['Category'] == 'Kurtis']\n",
    "test_df_c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2810067c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:24:48.467398Z",
     "iopub.status.busy": "2024-10-29T06:24:48.467056Z",
     "iopub.status.idle": "2024-10-29T06:29:28.777469Z",
     "shell.execute_reply": "2024-10-29T06:29:28.776294Z"
    },
    "papermill": {
     "duration": 283.157418,
     "end_time": "2024-10-29T06:29:28.781322",
     "exception": false,
     "start_time": "2024-10-29T06:24:45.623904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 2460/2460 [04:38<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to process images is 278.78722310066223 seconds, which is 8.823933238257949 images per second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def load_model(model_path, num_classes_per_attr, device):\n",
    "    # Initialize the model architecture and load the saved weights\n",
    "    model = MultiLabelClassifier(num_classes_per_attr)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_label_encoders(encoder_path):\n",
    "    with open(encoder_path, 'rb') as f:\n",
    "        encoders = pickle.load(f)\n",
    "    return encoders\n",
    "\n",
    "def preprocess_image(image_path, image_size=(512,512)):\n",
    "    # Define image transformations (same as used during training)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512,512)),  # TODO: Change with (512, 512)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Open image and apply transformations\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def inference(image, model, label_encoders):\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "\n",
    "    # Decode predictions\n",
    "    predicted_labels = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        # Attribute name should match the encoder dictionary keys like 'attr_1', 'attr_2', etc.\n",
    "        attr_name = f'attr_{i + 1}'\n",
    "        if attr_name in label_encoders.encoders:\n",
    "            decoded_label = label_encoders.encoders[attr_name].inverse_transform([predicted.item()])[0]\n",
    "            predicted_labels.append(decoded_label)\n",
    "        else:\n",
    "            raise KeyError(f\"Encoder for {attr_name} not found in the loaded label encoders.\")\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# Load the model and encoders once\n",
    "model_path = \"best_model_c3.pth\"\n",
    "encoder_path = \"/kaggle/working/label_encoders_c3.pkl\"\n",
    "num_classes_per_attr = [14, 3, 3, 3, 3, 3, 3, 4, 3]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = load_model(model_path, num_classes_per_attr, device)\n",
    "label_encoders = load_label_encoders(encoder_path)\n",
    "\n",
    "image_dir = \"/kaggle/input/test_images\"\n",
    "preds = {f'attr_{i}': [] for i in range(1, 10)}\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for val in tqdm(test_df_c3['id'], desc='Processing Images', total=len(test_df_c3)):\n",
    "    image_path = f\"{image_dir}/{str(val).zfill(6)}.jpg\"\n",
    "    image = preprocess_image(image_path).to(device)  # Preprocess and send image to device\n",
    "    predictions = inference(image, model, label_encoders)  # Use the already loaded model and encoders\n",
    "    for i in range(1, 10):\n",
    "        preds[f'attr_{i}'].append(predictions[i-1])\n",
    "\n",
    "print(f'Time taken to process images is {time.time() - t1} seconds, which is {len(test_df_c3) / (time.time() - t1)} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6140fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:29:35.311601Z",
     "iopub.status.busy": "2024-10-29T06:29:35.310832Z",
     "iopub.status.idle": "2024-10-29T06:29:35.336784Z",
     "shell.execute_reply": "2024-10-29T06:29:35.335968Z"
    },
    "papermill": {
     "duration": 3.23632,
     "end_time": "2024-10-29T06:29:35.338740",
     "exception": false,
     "start_time": "2024-10-29T06:29:32.102420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10889</th>\n",
       "      <td>11155</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>11156</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>11157</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>11158</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>11159</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>13610</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>blue</td>\n",
       "      <td>a-line</td>\n",
       "      <td>knee length</td>\n",
       "      <td>party</td>\n",
       "      <td>net</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>13611</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>blue</td>\n",
       "      <td>a-line</td>\n",
       "      <td>knee length</td>\n",
       "      <td>daily</td>\n",
       "      <td>net</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13346</th>\n",
       "      <td>13612</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>maroon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>13613</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13348</th>\n",
       "      <td>13614</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2460 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category      attr_1  attr_2       attr_3 attr_4 attr_5 attr_6  \\\n",
       "10889  11155   Kurtis         red     NaN          NaN  daily    NaN    NaN   \n",
       "10890  11156   Kurtis      purple     NaN          NaN  daily    NaN    NaN   \n",
       "10891  11157   Kurtis       black     NaN          NaN  daily    NaN  solid   \n",
       "10892  11158   Kurtis  multicolor     NaN          NaN  daily    NaN    NaN   \n",
       "10893  11159   Kurtis  multicolor     NaN          NaN  daily    NaN    NaN   \n",
       "...      ...      ...         ...     ...          ...    ...    ...    ...   \n",
       "13344  13610   Kurtis        blue  a-line  knee length  party    net  solid   \n",
       "13345  13611   Kurtis        blue  a-line  knee length  daily    net  solid   \n",
       "13346  13612   Kurtis      maroon     NaN          NaN  daily    NaN    NaN   \n",
       "13347  13613   Kurtis         red     NaN          NaN  daily    NaN    NaN   \n",
       "13348  13614   Kurtis        blue     NaN          NaN  daily    NaN    NaN   \n",
       "\n",
       "      attr_7                 attr_8   attr_9  \n",
       "10889    NaN  three-quarter sleeves  regular  \n",
       "10890    NaN  three-quarter sleeves  regular  \n",
       "10891  solid  three-quarter sleeves  regular  \n",
       "10892    NaN  three-quarter sleeves  regular  \n",
       "10893    NaN  three-quarter sleeves  regular  \n",
       "...      ...                    ...      ...  \n",
       "13344  solid  three-quarter sleeves  regular  \n",
       "13345  solid  three-quarter sleeves  regular  \n",
       "13346    NaN  three-quarter sleeves  regular  \n",
       "13347    NaN  three-quarter sleeves  regular  \n",
       "13348    NaN  three-quarter sleeves  regular  \n",
       "\n",
       "[2460 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    test_df_c3[f'attr_{i}'] = preds[f'attr_{i}']\n",
    "test_df_c3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de70297f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:29:41.909745Z",
     "iopub.status.busy": "2024-10-29T06:29:41.909289Z",
     "iopub.status.idle": "2024-10-29T06:29:41.940962Z",
     "shell.execute_reply": "2024-10-29T06:29:41.939912Z"
    },
    "papermill": {
     "duration": 3.330766,
     "end_time": "2024-10-29T06:29:41.943664",
     "exception": false,
     "start_time": "2024-10-29T06:29:38.612898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df_c3.to_csv('test_validation_df_c3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c1480ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:29:48.504449Z",
     "iopub.status.busy": "2024-10-29T06:29:48.504029Z",
     "iopub.status.idle": "2024-10-29T06:34:04.994961Z",
     "shell.execute_reply": "2024-10-29T06:34:04.993897Z"
    },
    "papermill": {
     "duration": 259.779973,
     "end_time": "2024-10-29T06:34:05.000056",
     "exception": false,
     "start_time": "2024-10-29T06:29:45.220083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 2460/2460 [04:15<00:00,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to process images is 255.0995557308197 seconds, which is 9.64329330058428 images per second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def load_model(model_path, num_classes_per_attr, device):\n",
    "    # Initialize the model architecture and load the saved weights\n",
    "    model = MultiLabelClassifier(num_classes_per_attr)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_label_encoders(encoder_path):\n",
    "    with open(encoder_path, 'rb') as f:\n",
    "        encoders = pickle.load(f)\n",
    "    return encoders\n",
    "\n",
    "def preprocess_image(image_path, image_size=(512,512)):\n",
    "    # Define image transformations (same as used during training)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512,512)),  # TODO: Change with (512, 512)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Open image and apply transformations\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def inference(image, model, label_encoders):\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "\n",
    "    # Decode predictions\n",
    "    predicted_labels = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        # Attribute name should match the encoder dictionary keys like 'attr_1', 'attr_2', etc.\n",
    "        attr_name = f'attr_{i + 1}'\n",
    "        if attr_name in label_encoders.encoders:\n",
    "            decoded_label = label_encoders.encoders[attr_name].inverse_transform([predicted.item()])[0]\n",
    "            predicted_labels.append(decoded_label)\n",
    "        else:\n",
    "            raise KeyError(f\"Encoder for {attr_name} not found in the loaded label encoders.\")\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# Load the model and encoders once\n",
    "model_path = \"best_model_end_c3.pth\"\n",
    "encoder_path = \"/kaggle/working/label_encoders_c3.pkl\"\n",
    "num_classes_per_attr = [14, 3, 3, 3, 3, 3, 3, 4, 3]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = load_model(model_path, num_classes_per_attr, device)\n",
    "label_encoders = load_label_encoders(encoder_path)\n",
    "\n",
    "image_dir = \"/kaggle/input/test_images\"\n",
    "preds = {f'attr_{i}': [] for i in range(1, 10)}\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for val in tqdm(test_df_c3['id'], desc='Processing Images', total=len(test_df_c3)):\n",
    "    image_path = f\"{image_dir}/{str(val).zfill(6)}.jpg\"\n",
    "    image = preprocess_image(image_path).to(device)  # Preprocess and send image to device\n",
    "    predictions = inference(image, model, label_encoders)  # Use the already loaded model and encoders\n",
    "    for i in range(1, 10):\n",
    "        preds[f'attr_{i}'].append(predictions[i-1])\n",
    "\n",
    "print(f'Time taken to process images is {time.time() - t1} seconds, which is {len(test_df_c3) / (time.time() - t1)} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f735274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:34:11.830206Z",
     "iopub.status.busy": "2024-10-29T06:34:11.829813Z",
     "iopub.status.idle": "2024-10-29T06:34:11.858669Z",
     "shell.execute_reply": "2024-10-29T06:34:11.857534Z"
    },
    "papermill": {
     "duration": 3.452652,
     "end_time": "2024-10-29T06:34:11.860869",
     "exception": false,
     "start_time": "2024-10-29T06:34:08.408217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10889</th>\n",
       "      <td>11155</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>red</td>\n",
       "      <td>a-line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>solid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>11156</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>maroon</td>\n",
       "      <td>a-line</td>\n",
       "      <td>knee length</td>\n",
       "      <td>daily</td>\n",
       "      <td>net</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891</th>\n",
       "      <td>11157</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>black</td>\n",
       "      <td>a-line</td>\n",
       "      <td>calf length</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>11158</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10893</th>\n",
       "      <td>11159</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>13610</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>net</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>13611</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>blue</td>\n",
       "      <td>straight</td>\n",
       "      <td>knee length</td>\n",
       "      <td>daily</td>\n",
       "      <td>net</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13346</th>\n",
       "      <td>13612</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>maroon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>default</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>13613</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13348</th>\n",
       "      <td>13614</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2460 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category      attr_1    attr_2       attr_3 attr_4 attr_5 attr_6  \\\n",
       "10889  11155   Kurtis         red    a-line          NaN  daily    NaN  solid   \n",
       "10890  11156   Kurtis      maroon    a-line  knee length  daily    net  solid   \n",
       "10891  11157   Kurtis       black    a-line  calf length  daily    NaN    NaN   \n",
       "10892  11158   Kurtis  multicolor       NaN          NaN  daily    NaN    NaN   \n",
       "10893  11159   Kurtis  multicolor       NaN          NaN  daily    NaN    NaN   \n",
       "...      ...      ...         ...       ...          ...    ...    ...    ...   \n",
       "13344  13610   Kurtis        blue       NaN          NaN  daily    net  solid   \n",
       "13345  13611   Kurtis        blue  straight  knee length  daily    net  solid   \n",
       "13346  13612   Kurtis      maroon       NaN          NaN  daily    NaN    NaN   \n",
       "13347  13613   Kurtis         red       NaN          NaN  daily    NaN    NaN   \n",
       "13348  13614   Kurtis        blue       NaN          NaN  daily    NaN    NaN   \n",
       "\n",
       "        attr_7                 attr_8   attr_9  \n",
       "10889      NaN  three-quarter sleeves  regular  \n",
       "10890    solid  three-quarter sleeves  regular  \n",
       "10891      NaN  three-quarter sleeves  regular  \n",
       "10892      NaN  three-quarter sleeves  regular  \n",
       "10893      NaN  three-quarter sleeves  regular  \n",
       "...        ...                    ...      ...  \n",
       "13344    solid  three-quarter sleeves  regular  \n",
       "13345    solid  three-quarter sleeves  regular  \n",
       "13346  default  three-quarter sleeves  regular  \n",
       "13347      NaN  three-quarter sleeves  regular  \n",
       "13348      NaN  three-quarter sleeves  regular  \n",
       "\n",
       "[2460 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    test_df_c3[f'attr_{i}'] = preds[f'attr_{i}']\n",
    "test_df_c3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd48743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:34:18.700811Z",
     "iopub.status.busy": "2024-10-29T06:34:18.699961Z",
     "iopub.status.idle": "2024-10-29T06:34:18.723583Z",
     "shell.execute_reply": "2024-10-29T06:34:18.722756Z"
    },
    "papermill": {
     "duration": 3.421389,
     "end_time": "2024-10-29T06:34:18.725784",
     "exception": false,
     "start_time": "2024-10-29T06:34:15.304395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df_c3.to_csv('test_df_c3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329a1c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T06:34:25.621745Z",
     "iopub.status.busy": "2024-10-29T06:34:25.621278Z",
     "iopub.status.idle": "2024-10-29T06:34:25.630694Z",
     "shell.execute_reply": "2024-10-29T06:34:25.629714Z"
    },
    "papermill": {
     "duration": 3.428727,
     "end_time": "2024-10-29T06:34:25.632769",
     "exception": false,
     "start_time": "2024-10-29T06:34:22.204042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import pickle\n",
    "# import csv\n",
    "# import time\n",
    "\n",
    "# final_time = 0\n",
    "# # Map categories to corresponding attribute columns (e.g., c1, c2, c3)\n",
    "# category_to_attributes = {\n",
    "#     'Men Tshirts': 'c1',\n",
    "#     'Sarees': 'c2',\n",
    "#     'Kurtis': 'c3',\n",
    "#     'Women Tshirts': 'c4',\n",
    "#     'Women Tops & Tunics': 'c5',\n",
    "# }\n",
    "\n",
    "# # Dummy value for missing attributes\n",
    "# DUMMY_VALUE = \"dummy_value\"\n",
    "\n",
    "# def load_model(model_path, num_classes_per_attr, device):\n",
    "#     model = MultiLabelClassifier(num_classes_per_attr)\n",
    "#     model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     return model\n",
    "\n",
    "# def load_label_encoders(encoder_path):\n",
    "#     with open(encoder_path, 'rb') as f:\n",
    "#         encoders = pickle.load(f)\n",
    "#     return encoders\n",
    "\n",
    "# def preprocess_image(image_path, image_size=(384,384)):\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize(image_size),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = transform(image)\n",
    "#     image = image.unsqueeze(0)  # Add batch dimension\n",
    "#     return image\n",
    "\n",
    "# def inference(image_path, model, label_encoders, num_classes_per_attr, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "#     image = preprocess_image(image_path).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(image)\n",
    "\n",
    "#     predicted_labels = []\n",
    "#     for i, output in enumerate(outputs):\n",
    "#         _, predicted = torch.max(output, 1)\n",
    "#         attr_name = f'attr_{i+1}'\n",
    "#         if attr_name in label_encoders.encoders:\n",
    "#             decoded_label = label_encoders.encoders[attr_name].inverse_transform([predicted.item()])[0]\n",
    "#             predicted_labels.append(decoded_label)\n",
    "#         else:\n",
    "#             predicted_labels.append(DUMMY_VALUE)\n",
    "    \n",
    "#     return predicted_labels\n",
    "\n",
    "# def make_predictions_for_dataset(df, model_paths, encoder_paths, output_path, image_dir, num_classes_per_attr_list, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "#     final_time = 0\n",
    "#     all_models = []\n",
    "#     all_label_encoders = []\n",
    "    \n",
    "#     # Load models and encoders for each attribute (c1 to c5)\n",
    "#     for model_path, encoder_path, num_classes_per_attr in zip(model_paths, encoder_paths, num_classes_per_attr_list):\n",
    "#         model = load_model(model_path, num_classes_per_attr, device)\n",
    "#         label_encoders = load_label_encoders(encoder_path)\n",
    "#         all_models.append(model)\n",
    "#         all_label_encoders.append(label_encoders)\n",
    "    \n",
    "#     all_predictions = []\n",
    "    \n",
    "#     for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Making predictions\"):\n",
    "#         category = row['Category']\n",
    "#         attribute_key = category_to_attributes.get(category, None)\n",
    "#         if attribute_key:\n",
    "#             # Determine which model and encoder to use based on the category\n",
    "#             attribute_idx = int(attribute_key[1]) - 1  # Example: 'c1' -> index 0, 'c2' -> index 1, etc.\n",
    "#             model = all_models[attribute_idx]\n",
    "#             label_encoders = all_label_encoders[attribute_idx]\n",
    "#             num_classes_per_attr = num_classes_per_attr_list[attribute_idx]\n",
    "#             image_path = f\"{image_dir}/{str(row['id']).zfill(6)}.jpg\"  \n",
    "            \n",
    "#             try:\n",
    "#                 t1 = time.time()\n",
    "#                 predictions = inference(image_path, model, label_encoders, num_classes_per_attr, device)\n",
    "#                 final_time = final_time + time.time() -t1 \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error with image {image_path}: {e}\")\n",
    "#                 predictions = [DUMMY_VALUE] * len(num_classes_per_attr)  # Fallback in case of error\n",
    "#         else:\n",
    "#             predictions = [DUMMY_VALUE] * len(num_classes_per_attr_list[0])  # Handle if category has no mapping\n",
    "            \n",
    "#         # Pad the predictions to ensure each row has 10 attributes\n",
    "#         while len(predictions) < 10:\n",
    "#             predictions.append(DUMMY_VALUE)\n",
    "        \n",
    "#         all_predictions.append([row['id']] + predictions)\n",
    "#     # Save predictions to CSV\n",
    "#     with open(output_path, 'w', newline='') as csvfile:\n",
    "#         writer = csv.writer(csvfile)\n",
    "#         header = ['id'] + [f'c{i+1}' for i in range(10)]  # Fixed number of attributes as 10\n",
    "#         writer.writerow(header)\n",
    "#         writer.writerows(all_predictions)\n",
    "#     print(f\"Predictions saved to {output_path}\")\n",
    "#     print(f\"Total model predictions time in seconds {final_time} and images predicted per second {len(test_df)/final_time}\")\n",
    "\n",
    "# # Example usage\n",
    "# dataset_path = '/kaggle/input/meesho/test.csv'  # Path to your dataset\n",
    "# model_paths = ['/kaggle/working/best_model_c1.pth', '/kaggle/working/best_model_c2.pth', '/kaggle/working/best_model_c3.pth', '/kaggle/working/best_model_c4.pth', '/kaggle/working/best_model_c5.pth']\n",
    "# encoder_paths = ['/kaggle/working/label_encoders_c1.pkl', '/kaggle/working/label_encoders_c2.pkl', '/kaggle/working/label_encoders_c3.pkl', '/kaggle/working/label_encoders_c4.pkl', '/kaggle/working/label_encoders_c5.pkl']\n",
    "# output_path = '/kaggle/working/output_predictions.csv'  # Path to save predictions\n",
    "# image_dir = '/kaggle/input/meesho/test_images'  # Directory containing images\n",
    "# num_classes_per_attr_list = [\n",
    "#     [5, 3, 3, 4, 3],  # For c1\n",
    "#     [5, 7, 4, 9, 5, 4, 5, 6, 10, 3],  # For c2\n",
    "#     [14, 3, 3, 3, 3, 3, 3, 4, 3],  # For c3\n",
    "#     [8, 4, 4, 4, 7, 4, 3, 3],  # For c4\n",
    "#     [13, 5, 3, 8, 3, 4, 7, 5, 5, 7],  # For c5\n",
    "# ]\n",
    "\n",
    "\n",
    "# test_df = pd.read_csv(dataset_path)\n",
    "\n",
    "# make_predictions_for_dataset(test_df, model_paths, encoder_paths, output_path, image_dir, num_classes_per_attr_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d05208",
   "metadata": {
    "papermill": {
     "duration": 3.212267,
     "end_time": "2024-10-29T06:34:32.374662",
     "exception": false,
     "start_time": "2024-10-29T06:34:29.162395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5923426,
     "sourceId": 9689319,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39437.879367,
   "end_time": "2024-10-29T06:34:38.252320",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-28T19:37:20.372953",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11864aaf32994b65b89dc3ed4f968c9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f0eab7cb4fa4724832342ce31e60c23",
       "placeholder": "​",
       "style": "IPY_MODEL_5b8fd9650b514960bfe6b4158aee3863",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "149e1c9a5d6e4cfca3742db062545dac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1581d846ca014f278d1ae56c4567349a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1674cef0064a47b8a4da0ecf7de68dd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae72ecf325784199bd9c78981ac9eb23",
       "max": 354492753.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7447cbd8719486b8494515350a7246d",
       "value": 354492753.0
      }
     },
     "22f6bb458378444b8cc9ae49acc53fcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f356a9e8f78e4953963a6b46e591b832",
       "placeholder": "​",
       "style": "IPY_MODEL_149e1c9a5d6e4cfca3742db062545dac",
       "value": " 354M/354M [00:01&lt;00:00, 245MB/s]"
      }
     },
     "28f3a7b9eabc4e2686e0e058a375c4df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "33367af0a4d24307b77e282ccf49006d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1581d846ca014f278d1ae56c4567349a",
       "placeholder": "​",
       "style": "IPY_MODEL_62607cdf08d24db4bded6f463b93454a",
       "value": "config.json: 100%"
      }
     },
     "557a42d7af434a02a71fce7b58e0adb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9708adad26d460892d7f84f977678bb",
       "max": 69643.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d6ccbe61028240a69731512338121173",
       "value": 69643.0
      }
     },
     "57df8a0ed1ea4a0789213ceba10d6585": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11864aaf32994b65b89dc3ed4f968c9d",
        "IPY_MODEL_1674cef0064a47b8a4da0ecf7de68dd9",
        "IPY_MODEL_22f6bb458378444b8cc9ae49acc53fcc"
       ],
       "layout": "IPY_MODEL_6f7efe6deda243f2b6166d587770145e"
      }
     },
     "5b8fd9650b514960bfe6b4158aee3863": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62607cdf08d24db4bded6f463b93454a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f7efe6deda243f2b6166d587770145e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74809382d2554a5590443e0291470bb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_33367af0a4d24307b77e282ccf49006d",
        "IPY_MODEL_557a42d7af434a02a71fce7b58e0adb8",
        "IPY_MODEL_b2b353118a7349a88c70f5ca53647b9c"
       ],
       "layout": "IPY_MODEL_9a20af6ee68244ddb01b0ced701e827e"
      }
     },
     "8f0eab7cb4fa4724832342ce31e60c23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a20af6ee68244ddb01b0ced701e827e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9aba1d7b2424c8e881ee12ef5c34e73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae72ecf325784199bd9c78981ac9eb23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2b353118a7349a88c70f5ca53647b9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a9aba1d7b2424c8e881ee12ef5c34e73",
       "placeholder": "​",
       "style": "IPY_MODEL_28f3a7b9eabc4e2686e0e058a375c4df",
       "value": " 69.6k/69.6k [00:00&lt;00:00, 2.45MB/s]"
      }
     },
     "c9708adad26d460892d7f84f977678bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6ccbe61028240a69731512338121173": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f356a9e8f78e4953963a6b46e591b832": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7447cbd8719486b8494515350a7246d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
