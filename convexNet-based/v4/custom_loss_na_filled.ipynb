{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:17.745924Z",
     "iopub.status.busy": "2024-11-08T06:18:17.745546Z",
     "iopub.status.idle": "2024-11-08T06:18:36.508409Z",
     "shell.execute_reply": "2024-11-08T06:18:36.507455Z",
     "shell.execute_reply.started": "2024-11-08T06:18:17.745884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import cv2\n",
    "from transformers import AutoImageProcessor\n",
    "from tqdm import tqdm \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from itertools import cycle\n",
    "\n",
    "from transformers import ConvNextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.511809Z",
     "iopub.status.busy": "2024-11-08T06:18:36.511166Z",
     "iopub.status.idle": "2024-11-08T06:18:36.518608Z",
     "shell.execute_reply": "2024-11-08T06:18:36.517689Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.511769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pre-defined\n",
    "category_dict = {'c1':'Men Tshirts', 'c2':'Sarees', 'c3': 'Kurtis', 'c4': 'Women Tshirts', 'c5': 'Women Tops & Tunics'}\n",
    "semi_classes_dict = {'c1':[4, 2, 2, 3, 2], 'c2':[4, 6, 3, 8, 4, 3, 4, 5, 9, 2], 'c3': [13, 2, 2, 2, 2, 2, 2, 3, 2], 'c4': [7, 3, 3, 3, 6, 3, 2, 2], 'c5': [12, 4, 2, 7, 2, 3, 6, 4, 4, 6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.520030Z",
     "iopub.status.busy": "2024-11-08T06:18:36.519742Z",
     "iopub.status.idle": "2024-11-08T06:18:36.550471Z",
     "shell.execute_reply": "2024-11-08T06:18:36.549511Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.519999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# set paths as per the set-up and Hyperparameters\n",
    "input_path = \"/kaggle/input/meesho\"\n",
    "working_path = \"/kaggle/working\"\n",
    "test_c_name = \"c1\"\n",
    "NUM_EPOCH = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_OF_SEMI_CLASSES_OF_COLUMNS = semi_classes_dict[test_c_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.552998Z",
     "iopub.status.busy": "2024-11-08T06:18:36.552610Z",
     "iopub.status.idle": "2024-11-08T06:18:36.823403Z",
     "shell.execute_reply": "2024-11-08T06:18:36.822398Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.552964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{input_path}/train.csv')\n",
    "df_test = pd.read_csv(f'{input_path}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.825499Z",
     "iopub.status.busy": "2024-11-08T06:18:36.824600Z",
     "iopub.status.idle": "2024-11-08T06:18:36.843854Z",
     "shell.execute_reply": "2024-11-08T06:18:36.842779Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.825458Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Men Tshirts', 'Sarees', 'Kurtis', 'Women Tshirts',\n",
       "       'Women Tops & Tunics'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_na_values_with_highest_class(df_obj):\n",
    "\n",
    "    # Select columns from 'attr_1' to the end of the dataframe\n",
    "    attr_columns = df_obj.loc[:, 'attr_1':]\n",
    "    \n",
    "    # Replace NaN values with the most frequent class in each column\n",
    "    for col in attr_columns.columns:\n",
    "        # Find the most frequent value in the column\n",
    "        highest_class = attr_columns[col].value_counts().idxmax()\n",
    "        # Replace NaN values in the column with the most frequent value\n",
    "        df_obj[col].fillna(highest_class, inplace=True)\n",
    "\n",
    "    return df_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.845476Z",
     "iopub.status.busy": "2024-11-08T06:18:36.845091Z",
     "iopub.status.idle": "2024-11-08T06:18:36.853498Z",
     "shell.execute_reply": "2024-11-08T06:18:36.852553Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.845433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def do_preprocessing(test_c_name, test_category):\n",
    "    df_sub = df_train[df_train['Category'] == test_category]\n",
    "    print(df_sub.info())\n",
    "    df_sub.dropna(axis=1, how='all', inplace=True)\n",
    "    df_sub = replace_na_values_with_highest_class(df_obj = df_sub)\n",
    "    print(df_sub.info())\n",
    "    return df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.855263Z",
     "iopub.status.busy": "2024-11-08T06:18:36.854945Z",
     "iopub.status.idle": "2024-11-08T06:18:36.928975Z",
     "shell.execute_reply": "2024-11-08T06:18:36.928079Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.855232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7267 entries, 0 to 7266\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7267 non-null   int64 \n",
      " 1   Category  7267 non-null   object\n",
      " 2   len       7267 non-null   int64 \n",
      " 3   attr_1    6010 non-null   object\n",
      " 4   attr_2    6144 non-null   object\n",
      " 5   attr_3    5791 non-null   object\n",
      " 6   attr_4    5949 non-null   object\n",
      " 7   attr_5    5977 non-null   object\n",
      " 8   attr_6    0 non-null      object\n",
      " 9   attr_7    0 non-null      object\n",
      " 10  attr_8    0 non-null      object\n",
      " 11  attr_9    0 non-null      object\n",
      " 12  attr_10   0 non-null      object\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 794.8+ KB\n",
      "None\n",
      "\n",
      "Number of features for original df: [4, 2, 2, 3, 2]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4575 entries, 0 to 5488\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        4575 non-null   int64 \n",
      " 1   Category  4575 non-null   object\n",
      " 2   len       4575 non-null   int64 \n",
      " 3   attr_1    4575 non-null   object\n",
      " 4   attr_2    4575 non-null   object\n",
      " 5   attr_3    4575 non-null   object\n",
      " 6   attr_4    4575 non-null   object\n",
      " 7   attr_5    4575 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 321.7+ KB\n",
      "None\n",
      "\n",
      "Number of features for new df: [4, 2, 2, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "if test_c_name == \"c1\":\n",
    "    df_c1 = do_preprocessing(test_c_name, category_dict[test_c_name])\n",
    "elif test_c_name == \"c2\":\n",
    "    df_c2 = do_preprocessing(test_c_name, category_dict[test_c_name])\n",
    "elif test_c_name == \"c3\":\n",
    "    df_c3 = do_preprocessing(test_c_name, category_dict[test_c_name])\n",
    "elif test_c_name == \"c4\":\n",
    "    df_c4 = do_preprocessing(test_c_name, category_dict[test_c_name])\n",
    "elif test_c_name == \"c5\":\n",
    "    df_c5 = do_preprocessing(test_c_name, category_dict[test_c_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.930800Z",
     "iopub.status.busy": "2024-11-08T06:18:36.930434Z",
     "iopub.status.idle": "2024-11-08T06:18:36.956579Z",
     "shell.execute_reply": "2024-11-08T06:18:36.955748Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.930758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LabelEncoderDict:\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        \n",
    "    def fit(self, df, columns):\n",
    "        \"\"\"Fit label encoders for each column\"\"\"\n",
    "        for col in columns:\n",
    "            le = LabelEncoder()\n",
    "            valid_labels = df[col].unique().tolist()\n",
    "            le.fit(valid_labels)\n",
    "            self.encoders[col] = le\n",
    "            \n",
    "    def transform(self, df, columns):\n",
    "        \"\"\"Transform labels using fitted encoders\"\"\"\n",
    "        encoded = np.zeros((len(df), len(columns)))\n",
    "        for i, col in enumerate(columns):\n",
    "            series = df[col].copy()\n",
    "            encoded[:, i] = self.encoders[col].transform(series)\n",
    "        return encoded\n",
    "    \n",
    "    def get_num_classes(self, column):\n",
    "        \"\"\"Get number of classes for a specific column\"\"\"\n",
    "        return len(self.encoders[column].classes_)\n",
    "\n",
    "\n",
    "class MultiLabelImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform_basic=None, transform_augmented=None, attr_columns=10, do_transform=True):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform_basic = transform_basic  # Basic transform without augmentation\n",
    "        self.transform_augmented = transform_augmented  # Augmented transform with augmentation\n",
    "        self.attr_columns = attr_columns\n",
    "        self.do_transform = do_transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path\n",
    "        img_name = str(self.df.iloc[idx]['id']).zfill(6)\n",
    "        img_path = os.path.join(self.image_dir, f\"{img_name}.jpg\")\n",
    "\n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (384, 384))\n",
    "\n",
    "\n",
    "        # Apply random probability to choose between augmentation or not\n",
    "        if  self.do_transform and (random.random() > 0.5):\n",
    "            if self.transform_augmented:\n",
    "                image = self.transform_augmented(image)         \n",
    "        else:\n",
    "            if self.transform_basic:\n",
    "                image = self.transform_basic(image)\n",
    "        # Ensure labels are integers and convert to tensor\n",
    "        labels = torch.tensor(self.df.iloc[idx][self.attr_columns].astype(int).values, dtype=torch.long)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "# The rest of your code remains the same.\n",
    "# Define transforms, data loaders, etc.\n",
    "\n",
    "def prepare_data(df, image_dir, batch_size=32, test_size=0.1, num_attr_columns=10):\n",
    "    \"\"\"\n",
    "    Prepare data loaders and label encoders\n",
    "    \"\"\"\n",
    "    # Define attribute columns\n",
    "    attr_columns = [f'attr_{i}' for i in range(1, num_attr_columns+1)]  # TODO: Adjust number of columns\n",
    "    \n",
    "    # Create and fit label encoders\n",
    "    label_encoders = LabelEncoderDict()\n",
    "    label_encoders.fit(df, attr_columns)\n",
    "    \n",
    "    # Transform labels\n",
    "    encoded_labels = label_encoders.transform(df, attr_columns)\n",
    "    df_encoded = df.copy()\n",
    "    for i, col in enumerate(attr_columns):\n",
    "        df_encoded[col] = encoded_labels[:, i]\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df = train_test_split(df_encoded, test_size=test_size, random_state=24)\n",
    "    \n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),  # Resize to 512x512\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    transform_augmented = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),  # Resize to 512x512\n",
    "        transforms.RandomHorizontalFlip(p=0.9),  # 90% chance of horizontal flipping\n",
    "        transforms.RandomRotation(degrees=5),  # Rotate by up to 20 degrees\n",
    "        transforms.RandomResizedCrop(size=(384, 384), scale=(0.8, 1.0)),  # Randomly crop and resize\n",
    "        transforms.RandomPerspective(distortion_scale=0.1, p=0.5),  # Apply perspective distortion\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15), shear=5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = MultiLabelImageDataset(\n",
    "        train_df,\n",
    "        image_dir,\n",
    "        transform_basic=transform,\n",
    "        transform_augmented=transform_augmented,\n",
    "        attr_columns=attr_columns\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultiLabelImageDataset(\n",
    "        val_df,\n",
    "        image_dir,\n",
    "        transform_basic=transform,\n",
    "        transform_augmented=transform_augmented,\n",
    "        attr_columns=attr_columns,\n",
    "        do_transform=False\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True)\n",
    "    \n",
    "    # Get number of classes for each attribute\n",
    "    num_classes_per_attr = [label_encoders.get_num_classes(col) for col in attr_columns]\n",
    "    \n",
    "    return train_loader, val_loader, label_encoders, num_classes_per_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:36.958289Z",
     "iopub.status.busy": "2024-11-08T06:18:36.957951Z",
     "iopub.status.idle": "2024-11-08T06:18:37.022701Z",
     "shell.execute_reply": "2024-11-08T06:18:37.021682Z",
     "shell.execute_reply.started": "2024-11-08T06:18:36.958255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from tqdm import tqdm \n",
    "from transformers import AutoImageProcessor, ConvNextV2ForImageClassification\n",
    "\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, num_classes_per_attr):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        \n",
    "        # Use ConvNeXt-Base with unfrozen backbone\n",
    "        self.backbone = ConvNextModel.from_pretrained(\"facebook/convnext-base-384-22k-1k\")\n",
    "        backbone_features = self.backbone.config.hidden_sizes[-1]  # 1024 for base model\n",
    "        \n",
    "        # Modified feature processing without fixed dimensions\n",
    "        self.feature_processor = nn.Sequential(\n",
    "            nn.Conv2d(backbone_features, 1024, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Complex classifier heads for each attribute\n",
    "        self.classifier_heads = nn.ModuleList()\n",
    "        for num_classes in num_classes_per_attr:\n",
    "            classifier_head = nn.Sequential(\n",
    "                # First branch - Spatial attention\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(1024, 512, kernel_size=3, padding=1, groups=32),\n",
    "                    nn.GELU(),\n",
    "                    nn.Conv2d(512, 512, kernel_size=3, padding=1, groups=32),\n",
    "                    nn.GELU(),\n",
    "                ),\n",
    "                \n",
    "                # Second branch - Channel attention (SE-like module)\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(512, 128),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(128, 512),\n",
    "                    nn.Sigmoid(),\n",
    "                ),\n",
    "                \n",
    "                # Combine branches and final classification\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(512, 1024),\n",
    "                    nn.LayerNorm(1024),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.4),\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.LayerNorm(512),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(512, num_classes)\n",
    "                )\n",
    "            )\n",
    "            self.classifier_heads.append(classifier_head)\n",
    "            \n",
    "    def forward(self, x,return_features=True):\n",
    "        # Extract features from ConvNeXt backbone\n",
    "        features = self.backbone(x).last_hidden_state\n",
    "        \n",
    "        # Process features\n",
    "        processed_features = self.feature_processor(features)\n",
    "        \n",
    "        outputs = []\n",
    "        for classifier_head in self.classifier_heads:\n",
    "            # Spatial attention branch\n",
    "            spatial_features = classifier_head[0](processed_features)\n",
    "            \n",
    "            # Channel attention branch\n",
    "            channel_attention = classifier_head[1](spatial_features)\n",
    "            channel_attention = channel_attention.view(-1, 512, 1, 1)\n",
    "            \n",
    "            # Apply channel attention and get final output\n",
    "            attended_features = spatial_features * channel_attention\n",
    "            output = classifier_head[2](attended_features)\n",
    "            outputs.append(output)\n",
    "        if return_features:\n",
    "            return outputs,processed_features\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    \n",
    "class MultiLabelCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelCELoss, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = 0\n",
    "        for i, output in enumerate(outputs):\n",
    "            loss += self.criterion(output, targets[:, i])\n",
    "        return loss / len(outputs)\n",
    "    \n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, lambda_mmd=0.1, chunk_size=1024):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.lambda_mmd = lambda_mmd\n",
    "        self.chunk_size = chunk_size\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs, labels, source_features, target_features):\n",
    "        # Calculate Cross-Entropy Loss\n",
    "        if isinstance(outputs, list):\n",
    "            ce_loss = 0\n",
    "            for i, output in enumerate(outputs):\n",
    "                if isinstance(labels, list):\n",
    "                    label = labels[i]\n",
    "                else:\n",
    "                    label = labels[:, i] if labels.dim() > 1 else labels\n",
    "                ce_loss += self.cross_entropy_loss(output, label)\n",
    "            ce_loss = ce_loss / len(outputs)\n",
    "        else:\n",
    "            ce_loss = self.cross_entropy_loss(outputs, labels)\n",
    "\n",
    "        # Calculate MMD Loss\n",
    "        mmd_loss = self.maximum_mean_discrepancy(source_features, target_features)\n",
    "        \n",
    "        # Combine losses (without CORAL)\n",
    "        total_loss = ce_loss + self.lambda_mmd * mmd_loss\n",
    "        \n",
    "        # Return zero for coral_loss to maintain compatibility\n",
    "        return total_loss, ce_loss, mmd_loss, torch.tensor(0.0, device=ce_loss.device)\n",
    "\n",
    "    def gaussian_kernel(self, x, y, bandwidth):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), -1)\n",
    "        \n",
    "        x_size = x.size(0)\n",
    "        y_size = y.size(0)\n",
    "        dim = x.size(1)\n",
    "        \n",
    "        x = x.unsqueeze(1)  # (x_size, 1, dim)\n",
    "        y = y.unsqueeze(0)  # (1, y_size, dim)\n",
    "        \n",
    "        kernel_input = (x - y).pow(2).sum(2).div(2 * bandwidth * bandwidth)\n",
    "        return torch.exp(-kernel_input)  # (x_size, y_size)\n",
    "\n",
    "    def maximum_mean_discrepancy(self, source_features, target_features):\n",
    "        # Ensure inputs are 2D tensors\n",
    "        if source_features.dim() > 2:\n",
    "            source_features = source_features.view(source_features.size(0), -1)\n",
    "        if target_features.dim() > 2:\n",
    "            target_features = target_features.view(target_features.size(0), -1)\n",
    "\n",
    "        # Get sizes\n",
    "        batch_source = source_features.size(0)\n",
    "        batch_target = target_features.size(0)\n",
    "        dim = source_features.size(1)\n",
    "\n",
    "        # Initialize MMD\n",
    "        mmd = torch.tensor(0., device=source_features.device)\n",
    "\n",
    "        # Use multiple kernel bandwidths\n",
    "        bandwidths = [dim * (2 ** i) for i in range(-3, 3)]\n",
    "\n",
    "        for bandwidth in bandwidths:\n",
    "            # Process source-source\n",
    "            source_sum = 0\n",
    "            for i in range(0, batch_source, self.chunk_size):\n",
    "                end = min(i + self.chunk_size, batch_source)\n",
    "                chunk = source_features[i:end]\n",
    "                kernel = self.gaussian_kernel(chunk, source_features, bandwidth)\n",
    "                source_sum += kernel.sum().item()\n",
    "\n",
    "            # Process target-target\n",
    "            target_sum = 0\n",
    "            for i in range(0, batch_target, self.chunk_size):\n",
    "                end = min(i + self.chunk_size, batch_target)\n",
    "                chunk = target_features[i:end]\n",
    "                kernel = self.gaussian_kernel(chunk, target_features, bandwidth)\n",
    "                target_sum += kernel.sum().item()\n",
    "\n",
    "            # Process source-target\n",
    "            cross_sum = 0\n",
    "            for i in range(0, batch_source, self.chunk_size):\n",
    "                s_end = min(i + self.chunk_size, batch_source)\n",
    "                s_chunk = source_features[i:s_end]\n",
    "                \n",
    "                for j in range(0, batch_target, self.chunk_size):\n",
    "                    t_end = min(j + self.chunk_size, batch_target)\n",
    "                    t_chunk = target_features[j:t_end]\n",
    "                    \n",
    "                    kernel = self.gaussian_kernel(s_chunk, t_chunk, bandwidth)\n",
    "                    cross_sum += kernel.sum().item()\n",
    "\n",
    "            # Calculate bandwidth contribution to MMD\n",
    "            source_term = source_sum / (batch_source * batch_source)\n",
    "            target_term = target_sum / (batch_target * batch_target)\n",
    "            cross_term = 2 * cross_sum / (batch_source * batch_target)\n",
    "            \n",
    "            mmd = mmd + torch.tensor(source_term + target_term - cross_term, \n",
    "                                   device=source_features.device)\n",
    "\n",
    "            # Clear cache\n",
    "            if hasattr(torch.cuda, 'empty_cache'):\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        return mmd / len(bandwidths)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, num_classes_per_attr, model_type):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    criterion = CombinedLoss()\n",
    "    criterion2 = MultiLabelCELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Reduce learning rate on plateau\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    # Early stopping params\n",
    "    early_stopping_patience = 4\n",
    "    early_stopping_counter = 0\n",
    "    best_val_overall_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_predictions = [0] * len(num_classes_per_attr)\n",
    "        total_predictions = 0\n",
    "        overall_correct = 0\n",
    "\n",
    "        # Store true and predicted labels for metrics calculation\n",
    "        train_true_labels = [[] for _ in range(len(num_classes_per_attr))]\n",
    "        train_predicted_labels = [[] for _ in range(len(num_classes_per_attr))]\n",
    "\n",
    "        # Create cyclic iterator for validation data during training\n",
    "        val_cycle = cycle(val_loader)\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", unit=\"batch\") as t:\n",
    "            for images, labels in t:\n",
    "                # Get target domain batch\n",
    "                target_images, _ = next(val_cycle)\n",
    "                \n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                target_images = target_images.to(device)\n",
    "\n",
    "                # Forward pass on source domain (training data)\n",
    "                outputs, source_features = model(images, return_features=True)\n",
    "                \n",
    "                # Forward pass on target domain (validation data)\n",
    "                _, target_features = model(target_images, return_features=True)\n",
    "\n",
    "                # Calculate combined loss\n",
    "                loss, ce_loss, mmd_loss, coral_loss = criterion(outputs, labels, source_features, target_features)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "\n",
    "                all_labels_match = torch.ones(labels.size(0), dtype=torch.bool, device=device)\n",
    "                for i, output in enumerate(outputs):\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    correct_predictions[i] += (predicted == labels[:, i]).sum().item()\n",
    "                    all_labels_match &= (predicted == labels[:, i])\n",
    "\n",
    "                    train_true_labels[i].extend(labels[:, i].cpu().numpy())\n",
    "                    train_predicted_labels[i].extend(predicted.cpu().numpy())\n",
    "\n",
    "                overall_correct += all_labels_match.sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct_predictions = [0] * len(num_classes_per_attr)\n",
    "        val_total_predictions = 0\n",
    "        val_overall_correct = 0\n",
    "\n",
    "        val_true_labels = [[] for _ in range(len(num_classes_per_attr))]\n",
    "        val_predicted_labels = [[] for _ in range(len(num_classes_per_attr))]\n",
    "\n",
    "        with tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", unit=\"batch\") as v:\n",
    "            with torch.no_grad():\n",
    "                for images, labels in v:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images,return_features=False)\n",
    "                    loss = criterion2(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    v.set_postfix(loss=loss.item())\n",
    "\n",
    "                    all_labels_match_val = torch.ones(labels.size(0), dtype=torch.bool, device=device)\n",
    "                    for i, output in enumerate(outputs):\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        val_correct_predictions[i] += (predicted == labels[:, i]).sum().item()\n",
    "                        all_labels_match_val &= (predicted == labels[:, i])\n",
    "\n",
    "                        # Store validation labels for precision, recall, f1-score calculations\n",
    "                        val_true_labels[i].extend(labels[:, i].cpu().numpy())\n",
    "                        val_predicted_labels[i].extend(predicted.cpu().numpy())\n",
    "\n",
    "                    val_overall_correct += all_labels_match_val.sum().item()\n",
    "                    val_total_predictions += labels.size(0)\n",
    "                    \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        \n",
    "        for i in range(len(num_classes_per_attr)):\n",
    "            train_acc = 100 * correct_predictions[i] / total_predictions\n",
    "            val_acc = 100 * val_correct_predictions[i] / val_total_predictions\n",
    "\n",
    "            train_precision = precision_score(train_true_labels[i], train_predicted_labels[i], average='weighted')\n",
    "            train_recall = recall_score(train_true_labels[i], train_predicted_labels[i], average='weighted')\n",
    "            train_f1 = f1_score(train_true_labels[i], train_predicted_labels[i], average='weighted')\n",
    "\n",
    "            val_precision = precision_score(val_true_labels[i], val_predicted_labels[i], average='weighted')\n",
    "            val_recall = recall_score(val_true_labels[i], val_predicted_labels[i], average='weighted')\n",
    "            val_f1 = f1_score(val_true_labels[i], val_predicted_labels[i], average='weighted')\n",
    "\n",
    "            print(f'Attribute {i+1} - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "            print(f'Attribute {i+1} - Train Precision: {train_precision:.2f}, Train Recall: {train_recall:.2f}, Train F1-Score: {train_f1:.2f}')\n",
    "            print(f'Attribute {i+1} - Val Precision: {val_precision:.2f}, Val Recall: {val_recall:.2f}, Val F1-Score: {val_f1:.2f}')\n",
    "            print()\n",
    "\n",
    "        overall_train_acc = 100 * overall_correct / total_predictions\n",
    "        overall_val_acc = 100 * val_overall_correct / val_total_predictions\n",
    "        print(f'Overall Train Accuracy: {overall_train_acc:.2f}%')\n",
    "        print(f'Overall Validation Accuracy: {overall_val_acc:.2f}%')\n",
    "\n",
    "        # Early stopping logic\n",
    "        if overall_val_acc >= best_val_overall_acc:\n",
    "            best_val_overall_acc = overall_val_acc\n",
    "            torch.save(model.module.state_dict(), f'best_model_{model_type}.pth')\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        lr_scheduler.step(overall_val_acc)\n",
    "        \n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "    torch.save(model.module.state_dict(), f'best_model_end_{model_type}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:37.025945Z",
     "iopub.status.busy": "2024-11-08T06:18:37.025614Z",
     "iopub.status.idle": "2024-11-08T06:18:37.037366Z",
     "shell.execute_reply": "2024-11-08T06:18:37.036530Z",
     "shell.execute_reply.started": "2024-11-08T06:18:37.025913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "\n",
    "def main(test_c_name):\n",
    "    # Set image directory\n",
    "    image_dir = f'{input_path}/train_images'\n",
    "    # Initialize device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Define a function to train each model sequentially\n",
    "    def train_single_model(data, num_attr_columns, model_type):\n",
    "        # Prepare data\n",
    "        print(f\"Preparing data for {model_type}\")\n",
    "        train_loader, val_loader, label_encoders, num_classes_per_attr = prepare_data(data, image_dir, batch_size=8, num_attr_columns=num_attr_columns)\n",
    "        world_size = torch.cuda.device_count()\n",
    "        # Initialize the model\n",
    "        print(f\"Initializing model {model_type}\")\n",
    "        print(num_classes_per_attr)\n",
    "        model = MultiLabelClassifier(num_classes_per_attr).to(device)\n",
    "        # Define loss and optimizer\n",
    "        criterion = MultiLabelCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        # Train the model\n",
    "        print(f\"Training model {model_type}\")\n",
    "        train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCH, num_classes_per_attr=num_classes_per_attr, model_type=model_type)\n",
    "        # Save label encoders\n",
    "        with open(f'label_encoders_{model_type}.pkl', 'wb') as f:\n",
    "            pickle.dump(label_encoders, f)\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"number of classes for {model_type} is {num_classes_per_attr}\")\n",
    "        print(\"---------------------------------------------\")\n",
    "        # Free up memory\n",
    "        del model, train_loader, val_loader, label_encoders, num_classes_per_attr\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    if test_c_name == \"c1\":\n",
    "        train_single_model(df_c1, num_attr_columns=5, model_type=test_c_name)\n",
    "    elif test_c_name == \"c2\":\n",
    "        train_single_model(df_c2, num_attr_columns=10, model_type=test_c_name)\n",
    "    elif test_c_name == \"c3\":\n",
    "        train_single_model(df_c3, num_attr_columns=9, model_type=test_c_name)\n",
    "    elif test_c_name == \"c4\":\n",
    "        train_single_model(df_c4, num_attr_columns=8, model_type=test_c_name)\n",
    "    elif test_c_name == \"c5\":\n",
    "        train_single_model(df_c5, num_attr_columns=10, model_type=test_c_name)\n",
    "    else:\n",
    "        print(\"Please do check the name of category, something is wrong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:18:37.038796Z",
     "iopub.status.busy": "2024-11-08T06:18:37.038430Z",
     "iopub.status.idle": "2024-11-08T06:28:15.213173Z",
     "shell.execute_reply": "2024-11-08T06:28:15.212147Z",
     "shell.execute_reply.started": "2024-11-08T06:18:37.038754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for c1\n",
      "Initializing model c1\n",
      "[4, 2, 2, 3, 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89672f04e4dc4ccbb27fe3ddc855f916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa9f8adacba4e2bb66ee2840b070638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Training]: 100%|██████████| 514/514 [09:17<00:00,  1.09s/batch, loss=0.257]\n",
      "Epoch 1/1 [Validation]: 100%|██████████| 57/57 [00:14<00:00,  3.86batch/s, loss=0.429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Training Loss: 0.3553\n",
      "Validation Loss: 0.2405\n",
      "Attribute 1 - Train Acc: 57.13%, Val Acc: 67.54%\n",
      "Attribute 1 - Train Precision: 0.59, Train Recall: 0.57, Train F1-Score: 0.57\n",
      "Attribute 1 - Val Precision: 0.69, Val Recall: 0.68, Val F1-Score: 0.67\n",
      "\n",
      "Attribute 2 - Train Acc: 95.79%, Val Acc: 99.56%\n",
      "Attribute 2 - Train Precision: 0.96, Train Recall: 0.96, Train F1-Score: 0.96\n",
      "Attribute 2 - Val Precision: 1.00, Val Recall: 1.00, Val F1-Score: 1.00\n",
      "\n",
      "Attribute 3 - Train Acc: 94.82%, Val Acc: 97.81%\n",
      "Attribute 3 - Train Precision: 0.95, Train Recall: 0.95, Train F1-Score: 0.95\n",
      "Attribute 3 - Val Precision: 0.98, Val Recall: 0.98, Val F1-Score: 0.98\n",
      "\n",
      "Attribute 4 - Train Acc: 84.46%, Val Acc: 90.13%\n",
      "Attribute 4 - Train Precision: 0.85, Train Recall: 0.84, Train F1-Score: 0.82\n",
      "Attribute 4 - Val Precision: 0.91, Val Recall: 0.90, Val F1-Score: 0.90\n",
      "\n",
      "Attribute 5 - Train Acc: 98.08%, Val Acc: 97.37%\n",
      "Attribute 5 - Train Precision: 0.96, Train Recall: 0.98, Train F1-Score: 0.97\n",
      "Attribute 5 - Val Precision: 0.95, Val Recall: 0.97, Val F1-Score: 0.96\n",
      "\n",
      "Overall Train Accuracy: 45.91%\n",
      "Overall Validation Accuracy: 58.55%\n",
      "---------------------------------------------\n",
      "number of classes for c1 is [4, 2, 2, 3, 2]\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "main(test_c_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:28:15.269477Z",
     "iopub.status.busy": "2024-11-08T06:28:15.269205Z",
     "iopub.status.idle": "2024-11-08T06:28:15.289505Z",
     "shell.execute_reply": "2024-11-08T06:28:15.288633Z",
     "shell.execute_reply.started": "2024-11-08T06:28:15.269444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>3782</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>3783</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>3784</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>3785</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>3786</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3787 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     Category\n",
       "0        0  Men Tshirts\n",
       "1        1  Men Tshirts\n",
       "2        2  Men Tshirts\n",
       "3        3  Men Tshirts\n",
       "4        4  Men Tshirts\n",
       "...    ...          ...\n",
       "3782  3782  Men Tshirts\n",
       "3783  3783  Men Tshirts\n",
       "3784  3784  Men Tshirts\n",
       "3785  3785  Men Tshirts\n",
       "3786  3786  Men Tshirts\n",
       "\n",
       "[3787 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_semi = df_test[df_test['Category'] == category_dict[test_c_name]]\n",
    "test_df_semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:28:15.290908Z",
     "iopub.status.busy": "2024-11-08T06:28:15.290590Z",
     "iopub.status.idle": "2024-11-08T06:28:15.303974Z",
     "shell.execute_reply": "2024-11-08T06:28:15.303061Z",
     "shell.execute_reply.started": "2024-11-08T06:28:15.290873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def load_model(model_path, num_classes_per_attr, device):\n",
    "    # Initialize the model architecture and load the saved weights\n",
    "    model = MultiLabelClassifier(num_classes_per_attr)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_label_encoders(encoder_path):\n",
    "    with open(encoder_path, 'rb') as f:\n",
    "        encoders = pickle.load(f)\n",
    "    return encoders\n",
    "\n",
    "def preprocess_image(image_path, image_size=(512,512)):\n",
    "    # Define image transformations (same as used during training)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512,512)),  # TODO: Change with (512, 512)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Open image and apply transformations\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def inference(images, model, label_encoders):\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x=images,return_features=False)\n",
    "\n",
    "    # Decode predictions\n",
    "    predicted_labels = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        attr_name = f'attr_{i + 1}'\n",
    "        if attr_name in label_encoders.encoders:\n",
    "            decoded_label = label_encoders.encoders[attr_name].inverse_transform([predicted.item()])[0]\n",
    "            predicted_labels.append(decoded_label)\n",
    "        else:\n",
    "            raise KeyError(f\"Encoder for {attr_name} not found in the loaded label encoders.\")\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T06:28:15.306305Z",
     "iopub.status.busy": "2024-11-08T06:28:15.305863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   6%|▌         | 224/3787 [00:21<05:40, 10.48it/s]"
     ]
    }
   ],
   "source": [
    "model_path = f\"best_model_{test_c_name}.pth\"\n",
    "encoder_path = f\"{working_path}/label_encoders_{test_c_name}.pkl\"\n",
    "num_classes_per_attr = NUM_OF_SEMI_CLASSES_OF_COLUMNS\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = load_model(model_path, num_classes_per_attr, device)\n",
    "label_encoders = load_label_encoders(encoder_path)\n",
    "image_dir = f\"{input_path}/test_images\"\n",
    "interval = len(semi_classes_dict[test_c_name]) +1\n",
    "preds = {f'attr_{i}': [] for i in range(1,interval )}\n",
    "t1 = time.time()\n",
    "\n",
    "for val in tqdm(test_df_semi['id'], desc='Processing Images', total=len(test_df_semi)):\n",
    "    image_path = f\"{image_dir}/{str(val).zfill(6)}.jpg\"\n",
    "    image = preprocess_image(image_path).to(device)  # Preprocess and send image to device\n",
    "    predictions = inference(image, model, label_encoders)  # Use the already loaded model and encoders\n",
    "    for i in range(1, interval):\n",
    "        preds[f'attr_{i}'].append(predictions[i-1])\n",
    "print(f'Time taken to process images is {time.time() - t1} seconds, which is {len(test_df_semi) / (time.time() - t1)} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T05:26:21.391812Z",
     "iopub.status.busy": "2024-11-08T05:26:21.391307Z",
     "iopub.status.idle": "2024-11-08T05:26:21.412813Z",
     "shell.execute_reply": "2024-11-08T05:26:21.411834Z",
     "shell.execute_reply.started": "2024-11-08T05:26:21.391767Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>black</td>\n",
       "      <td>round</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>long sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>white</td>\n",
       "      <td>round</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>long sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>default</td>\n",
       "      <td>round</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>long sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>default</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>black</td>\n",
       "      <td>round</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>long sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>3782</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>3783</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>black</td>\n",
       "      <td>round</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>3784</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>default</td>\n",
       "      <td>polo</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>3785</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>default</td>\n",
       "      <td>round</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>3786</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>default</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3787 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     Category      attr_1 attr_2   attr_3   attr_4         attr_5\n",
       "0        0  Men Tshirts       black  round  printed  default   long sleeves\n",
       "1        1  Men Tshirts       white  round  printed  default   long sleeves\n",
       "2        2  Men Tshirts     default  round  printed  default   long sleeves\n",
       "3        3  Men Tshirts     default   polo    solid    solid  short sleeves\n",
       "4        4  Men Tshirts       black  round    solid    solid   long sleeves\n",
       "...    ...          ...         ...    ...      ...      ...            ...\n",
       "3782  3782  Men Tshirts  multicolor   polo    solid    solid  short sleeves\n",
       "3783  3783  Men Tshirts       black  round  printed  default  short sleeves\n",
       "3784  3784  Men Tshirts     default   polo  printed  default  short sleeves\n",
       "3785  3785  Men Tshirts     default  round    solid    solid  short sleeves\n",
       "3786  3786  Men Tshirts     default   polo    solid    solid  short sleeves\n",
       "\n",
       "[3787 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,interval):\n",
    "    test_df_semi[f'attr_{i}'] = preds[f'attr_{i}']\n",
    "test_df_semi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T05:26:30.225193Z",
     "iopub.status.busy": "2024-11-08T05:26:30.224799Z",
     "iopub.status.idle": "2024-11-08T05:26:30.250465Z",
     "shell.execute_reply": "2024-11-08T05:26:30.249570Z",
     "shell.execute_reply.started": "2024-11-08T05:26:30.225156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_semi.to_csv(f'test_validation_df_{test_c_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = f\"best_model_end_{test_c_name}.pth\"\n",
    "encoder_path = f\"{working_path}/label_encoders_{test_c_name}.pkl\"\n",
    "num_classes_per_attr = NUM_OF_SEMI_CLASSES_OF_COLUMNS\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = load_model(model_path, num_classes_per_attr, device)\n",
    "label_encoders = load_label_encoders(encoder_path)\n",
    "image_dir = f\"{input_path}/test_images\"\n",
    "preds = {f'attr_{i}': [] for i in range(1, interval)}\n",
    "t1 = time.time()\n",
    "for val in tqdm(test_df_semi['id'], desc='Processing Images', total=len(test_df_semi)):\n",
    "    image_path = f\"{image_dir}/{str(val).zfill(6)}.jpg\"\n",
    "    image = preprocess_image(image_path).to(device)  # Preprocess and send image to device\n",
    "    predictions = inference(image, model, label_encoders)  # Use the already loaded model and encoders\n",
    "    for i in range(1, interval):\n",
    "        preds[f'attr_{i}'].append(predictions[i-1])\n",
    "print(f'Time taken to process images is {time.time() - t1} seconds, which is {len(test_df_semi) / (time.time() - t1)} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,interval):\n",
    "    test_df_semi[f'attr_{i}'] = preds[f'attr_{i}']\n",
    "test_df_semi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_semi.to_csv(f'test_df_semi_{test_c_name}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5920841,
     "sourceId": 9685698,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
