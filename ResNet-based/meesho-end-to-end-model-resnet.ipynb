{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84705,"databundleVersionId":9755748,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:17.096533Z","iopub.execute_input":"2024-10-20T20:40:17.097262Z","iopub.status.idle":"2024-10-20T20:40:22.395586Z","shell.execute_reply.started":"2024-10-20T20:40:17.097208Z","shell.execute_reply":"2024-10-20T20:40:22.394741Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import warnings\n\n# Suppress all warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.397111Z","iopub.execute_input":"2024-10-20T20:40:22.397535Z","iopub.status.idle":"2024-10-20T20:40:22.402190Z","shell.execute_reply.started":"2024-10-20T20:40:22.397502Z","shell.execute_reply":"2024-10-20T20:40:22.401298Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')\ndf_test = pd.read_csv('/kaggle/input/visual-taxonomy/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.403389Z","iopub.execute_input":"2024-10-20T20:40:22.403779Z","iopub.status.idle":"2024-10-20T20:40:22.646527Z","shell.execute_reply.started":"2024-10-20T20:40:22.403733Z","shell.execute_reply":"2024-10-20T20:40:22.645673Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df_train['Category'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.648580Z","iopub.execute_input":"2024-10-20T20:40:22.649234Z","iopub.status.idle":"2024-10-20T20:40:22.667716Z","shell.execute_reply.started":"2024-10-20T20:40:22.649189Z","shell.execute_reply":"2024-10-20T20:40:22.666803Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['Men Tshirts', 'Sarees', 'Kurtis', 'Women Tshirts',\n       'Women Tops & Tunics'], dtype=object)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# df_train = df_train[:1000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.668785Z","iopub.execute_input":"2024-10-20T20:40:22.669091Z","iopub.status.idle":"2024-10-20T20:40:22.673471Z","shell.execute_reply.started":"2024-10-20T20:40:22.669060Z","shell.execute_reply":"2024-10-20T20:40:22.672482Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_c1 = df_train[df_train['Category'] == 'Men Tshirts']\ndf_c2 = df_train[df_train['Category'] == 'Sarees']\ndf_c3 = df_train[df_train['Category'] == 'Kurtis']\ndf_c4 = df_train[df_train['Category'] == 'Women Tshirts']\ndf_c5 = df_train[df_train['Category'] == 'Women Tops & Tunics']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.674596Z","iopub.execute_input":"2024-10-20T20:40:22.674903Z","iopub.status.idle":"2024-10-20T20:40:22.751496Z","shell.execute_reply.started":"2024-10-20T20:40:22.674872Z","shell.execute_reply":"2024-10-20T20:40:22.750703Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# df_c1 = df_c1[:1000]\n# df_c2 = df_c2[:1000]\n# df_c3 = df_c3[:1000]\n# df_c4 = df_c4[:1000]\n# df_c5 = df_c5[:1000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.752675Z","iopub.execute_input":"2024-10-20T20:40:22.753293Z","iopub.status.idle":"2024-10-20T20:40:22.758964Z","shell.execute_reply.started":"2024-10-20T20:40:22.753248Z","shell.execute_reply":"2024-10-20T20:40:22.757996Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# df_c1.drop(columns=['Category'])\n# df_c2.drop(columns=['Category'])\n# df_c3.drop(columns=['Category'])\n# df_c4.drop(columns=['Category'])\n# df_c5.drop(columns=['Category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.760460Z","iopub.execute_input":"2024-10-20T20:40:22.760948Z","iopub.status.idle":"2024-10-20T20:40:22.768631Z","shell.execute_reply.started":"2024-10-20T20:40:22.760904Z","shell.execute_reply":"2024-10-20T20:40:22.767791Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_c1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.769791Z","iopub.execute_input":"2024-10-20T20:40:22.770070Z","iopub.status.idle":"2024-10-20T20:40:22.794214Z","shell.execute_reply.started":"2024-10-20T20:40:22.770039Z","shell.execute_reply":"2024-10-20T20:40:22.793272Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   id     Category  len      attr_1 attr_2   attr_3   attr_4         attr_5  \\\n0   0  Men Tshirts    5     default  round  printed  default  short sleeves   \n1   1  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n2   2  Men Tshirts    5     default   polo    solid    solid  short sleeves   \n3   3  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n4   4  Men Tshirts    5  multicolor   polo    solid    solid  short sleeves   \n\n  attr_6 attr_7 attr_8 attr_9 attr_10  \n0    NaN    NaN    NaN    NaN     NaN  \n1    NaN    NaN    NaN    NaN     NaN  \n2    NaN    NaN    NaN    NaN     NaN  \n3    NaN    NaN    NaN    NaN     NaN  \n4    NaN    NaN    NaN    NaN     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"<h1>Common Model Architecture</h1>","metadata":{}},{"cell_type":"code","source":"class LabelEncoderDict:\n    def __init__(self):\n        self.encoders = {}\n        \n    def fit(self, df, columns):\n        \"\"\"Fit label encoders for each column\"\"\"\n        for col in columns:\n            le = LabelEncoder()\n            # Include NaN as a unique label by appending it to valid labels\n            valid_labels = df[col].dropna().unique().tolist()\n            valid_labels.append('NaN')  # Assign a label for NaN\n            le.fit(valid_labels)\n            self.encoders[col] = le\n            \n    def transform(self, df, columns):\n        \"\"\"Transform labels using fitted encoders\"\"\"\n        encoded = np.zeros((len(df), len(columns)))\n        for i, col in enumerate(columns):\n            series = df[col].copy()\n            # Replace NaNs with the string 'NaN' so they can be encoded\n            series = series.fillna('NaN')\n            encoded[:, i] = self.encoders[col].transform(series)\n        return encoded\n    \n    def get_num_classes(self, column):\n        \"\"\"Get number of classes for a specific column\"\"\"\n        return len(self.encoders[column].classes_)\n\n\nclass MultiLabelImageDataset(Dataset):\n    def __init__(self, df, image_dir, transform=None, attr_columns=10):\n        self.df = df\n        self.image_dir = image_dir\n        self.transform = transform\n        # TODO: Changes \n        self.attr_columns = attr_columns\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        # Get image path\n        img_name = str(self.df.iloc[idx]['id']).zfill(6)\n        img_path = os.path.join(self.image_dir, f\"{img_name}.jpg\")\n        \n        # Load image\n        try:\n            image = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            image = Image.new('RGB', (224, 224))  # TODO: Changes with (512, 512)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        # Ensure labels are integers and convert to tensor\n        labels = torch.tensor(self.df.iloc[idx][self.attr_columns].astype(int).values, dtype=torch.long)\n        \n        return image, labels\n\n\ndef prepare_data(df, image_dir, batch_size=32, test_size=0.2, num_attr_columns=10):\n    \"\"\"\n    Prepare data loaders and label encoders\n    \"\"\"\n    # Define attribute columns\n    attr_columns = [f'attr_{i}' for i in range(1, num_attr_columns+1)] # TODO: Changes with the number of column to consider\n    \n    # Create and fit label encoders\n    label_encoders = LabelEncoderDict()\n    label_encoders.fit(df, attr_columns)\n    \n    # Transform labels\n    encoded_labels = label_encoders.transform(df, attr_columns)\n    df_encoded = df.copy()\n    for i, col in enumerate(attr_columns):\n        df_encoded[col] = encoded_labels[:, i]\n    \n    # Split data\n    train_df, val_df = train_test_split(df_encoded, test_size=test_size, random_state=42)\n    \n    # Define transforms\n    transform = transforms.Compose([\n        transforms.Resize((256, 512)),  # TODO: Changes with (512, 512)\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Create datasets\n    train_dataset = MultiLabelImageDataset(\n        train_df,\n        image_dir,\n        transform=transform,\n        attr_columns=attr_columns\n    )\n    \n    val_dataset = MultiLabelImageDataset(\n        val_df,\n        image_dir,\n        transform=transform,\n        attr_columns=attr_columns\n    )\n    \n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    # Get number of classes for each attribute\n    num_classes_per_attr = [label_encoders.get_num_classes(col) for col in attr_columns]\n    \n    return train_loader, val_loader, label_encoders, num_classes_per_attr\n\nclass MultiLabelClassifier(nn.Module):\n    def __init__(self, num_classes_per_attr, pretrained=True):\n        super(MultiLabelClassifier, self).__init__()\n        self.backbone = models.resnet50(pretrained=pretrained) #Backbone model 1\n        num_features = self.backbone.fc.in_features\n        self.backbone = torch.nn.Sequential(*(list(self.backbone.children())[:-1]))\n        \n        # Create separate classifier heads for each attribute\n        self.classifier_heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(num_features, 512),\n                nn.ReLU(),\n                nn.Dropout(0.3),\n                nn.Linear(512, num_classes)\n            ) for num_classes in num_classes_per_attr\n        ])\n\n    def forward(self, x):\n        features = self.backbone(x)\n        features = features.view(features.size(0), -1)\n        return [head(features) for head in self.classifier_heads]\n\nclass MultiLabelCELoss(nn.Module):\n    def __init__(self):\n        super(MultiLabelCELoss, self).__init__()\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, outputs, targets):\n        # outputs is a list of predictions for each label\n        # targets is a tensor of shape (batch_size, num_labels)\n        loss = 0\n        for i, output in enumerate(outputs):\n            loss += self.criterion(output, targets[:, i])\n        return loss / len(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.797116Z","iopub.execute_input":"2024-10-20T20:40:22.797431Z","iopub.status.idle":"2024-10-20T20:40:22.822198Z","shell.execute_reply.started":"2024-10-20T20:40:22.797398Z","shell.execute_reply":"2024-10-20T20:40:22.821076Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\nclass MultiLabelClassifier(nn.Module):\n    def __init__(self, num_classes_per_attr, pretrained=True):\n        super(MultiLabelClassifier, self).__init__()\n        self.backbone = models.efficientnet_b2(pretrained=pretrained)\n        num_features = self.backbone.classifier[1].in_features\n        self.backbone = torch.nn.Sequential(*(list(self.backbone.children())[:-1]))\n        \n        self.feature_extractor = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.BatchNorm1d(num_features),\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 1024),\n            nn.ReLU(),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.4)\n        )\n        \n        self.shared_features = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3)\n        )\n        \n        self.classifier_heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(512, 256),\n                nn.ReLU(),\n                nn.BatchNorm1d(256),\n                nn.Dropout(0.2),\n                nn.Linear(256, num_classes)\n            ) for num_classes in num_classes_per_attr\n        ])\n\n    def forward(self, x):\n        features = self.backbone(x)\n        features = self.feature_extractor(features)\n        shared = self.shared_features(features)\n        \n        return [head(shared) for head in self.classifier_heads]\n\nclass MultiLabelCELoss(nn.Module):\n    def __init__(self):\n        super(MultiLabelCELoss, self).__init__()\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, outputs, targets):\n        loss = 0\n        for i, output in enumerate(outputs):\n            loss += self.criterion(output, targets[:, i])\n        return loss / len(outputs)\n\ndef train_model(model, train_loader, val_loader, num_epochs, num_classes_per_attr, model_type):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    criterion = MultiLabelCELoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, \n        max_lr=1e-3,\n        epochs=num_epochs,\n        steps_per_epoch=len(train_loader)\n    )\n    \n    best_val_loss = float('inf')\n    patience = 5\n    patience_counter = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        correct_predictions = [0] * len(num_classes_per_attr)\n        total_predictions = 0\n        overall_correct = 0  # To track instances where all labels match\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            train_loss += loss.item()\n            \n            # Check predictions for each attribute\n            all_labels_match = torch.ones(labels.size(0), dtype=torch.bool, device=device)  # For overall accuracy\n            for i, output in enumerate(outputs):\n                _, predicted = torch.max(output, 1)\n                correct_predictions[i] += (predicted == labels[:, i]).sum().item()\n                all_labels_match &= (predicted == labels[:, i])  # Track overall label match for this instance\n                \n            overall_correct += all_labels_match.sum().item()\n            total_predictions += labels.size(0)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0\n        val_correct_predictions = [0] * len(num_classes_per_attr)\n        val_total_predictions = 0\n        val_overall_correct = 0  # For validation overall accuracy\n        \n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                \n                all_labels_match_val = torch.ones(labels.size(0), dtype=torch.bool, device=device)  # For overall accuracy\n                for i, output in enumerate(outputs):\n                    _, predicted = torch.max(output, 1)\n                    val_correct_predictions[i] += (predicted == labels[:, i]).sum().item()\n                    all_labels_match_val &= (predicted == labels[:, i])  # Track overall label match\n                \n                val_overall_correct += all_labels_match_val.sum().item()\n                val_total_predictions += labels.size(0)\n        \n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n        \n        # Print accuracy for each attribute\n        for i in range(len(num_classes_per_attr)):\n            train_acc = 100 * correct_predictions[i] / total_predictions\n            val_acc = 100 * val_correct_predictions[i] / val_total_predictions\n            print(f'Attribute {i+1} - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n        \n        # Overall accuracy where all predicted labels match target labels\n        overall_train_acc = 100 * overall_correct / total_predictions\n        overall_val_acc = 100 * val_overall_correct / val_total_predictions\n        print(f'Overall Train Accuracy: {overall_train_acc:.2f}%')\n        print(f'Overall Validation Accuracy: {overall_val_acc:.2f}%')\n        \n        # Check for improvement and early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), f'best_model_{model_type}.pth')\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\"Early stopping triggered\")\n                break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:40:22.823410Z","iopub.execute_input":"2024-10-20T20:40:22.823719Z","iopub.status.idle":"2024-10-20T20:40:22.851535Z","shell.execute_reply.started":"2024-10-20T20:40:22.823674Z","shell.execute_reply":"2024-10-20T20:40:22.850647Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import pickle\nimport gc\n\ndef main(df_c1, df_c2, df_c3, df_c4, df_c5):\n    # Set image directory\n    image_dir = '/kaggle/input/visual-taxonomy/train_images'\n    \n    # Initialize device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Define a function to train each model sequentially\n    def train_single_model(data, num_attr_columns, model_type):\n        # Prepare data\n        print(f\"Preparing data for {model_type}\")\n        train_loader, val_loader, label_encoders, num_classes_per_attr = prepare_data(data, image_dir, batch_size=32, num_attr_columns=num_attr_columns)\n        \n        # Initialize the model\n        print(f\"Initializing model {model_type}\")\n        model = MultiLabelClassifier(num_classes_per_attr).to(device)\n        \n        # Define loss and optimizer\n        criterion = MultiLabelCELoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n        \n        # Train the model\n        print(f\"Training model {model_type}\")\n        train_model(model, train_loader, val_loader, num_epochs=5, num_classes_per_attr=num_classes_per_attr, model_type=model_type)\n        \n        # Save label encoders\n        with open(f'label_encoders_{model_type}.pkl', 'wb') as f:\n            pickle.dump(label_encoders, f)\n\n        print(\"---------------------------------------------\")\n        print(f\"number of classes for {model_type} is {num_classes_per_attr}\")\n        print(\"---------------------------------------------\")\n\n        # Free up memory\n        del model, train_loader, val_loader, label_encoders, num_classes_per_attr\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    # Train models one at a time\n    train_single_model(df_c1, num_attr_columns=5, model_type=\"c1\")\n    train_single_model(df_c2, num_attr_columns=10, model_type=\"c2\")\n    train_single_model(df_c3, num_attr_columns=9, model_type=\"c3\")\n    train_single_model(df_c4, num_attr_columns=8, model_type=\"c4\")\n    train_single_model(df_c5, num_attr_columns=10, model_type=\"c5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:44:46.590819Z","iopub.execute_input":"2024-10-20T20:44:46.591805Z","iopub.status.idle":"2024-10-20T20:44:46.603925Z","shell.execute_reply.started":"2024-10-20T20:44:46.591756Z","shell.execute_reply":"2024-10-20T20:44:46.602778Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"main(df_c1, df_c2, df_c3, df_c4, df_c5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:44:46.719455Z","iopub.execute_input":"2024-10-20T20:44:46.719853Z","iopub.status.idle":"2024-10-20T20:46:58.013557Z","shell.execute_reply.started":"2024-10-20T20:44:46.719812Z","shell.execute_reply":"2024-10-20T20:46:58.012753Z"}},"outputs":[{"name":"stdout","text":"Preparing data for c1\nInitializing model c1\nTraining model c1\nEpoch 1/1\nTraining Loss: 0.9935\nValidation Loss: 0.7883\nAttribute 1 - Train Acc: 39.38%, Val Acc: 52.00%\nAttribute 2 - Train Acc: 71.50%, Val Acc: 90.00%\nAttribute 3 - Train Acc: 67.88%, Val Acc: 90.50%\nAttribute 4 - Train Acc: 64.38%, Val Acc: 88.50%\nAttribute 5 - Train Acc: 40.12%, Val Acc: 14.50%\nOverall Train Accuracy: 11.38%\nOverall Validation Accuracy: 9.00%\n---------------------------------------------\nnumber of classes for c1 is [5, 3, 3, 4, 3]\n---------------------------------------------\nPreparing data for c2\nInitializing model c2\nTraining model c2\nEpoch 1/1\nTraining Loss: 1.6006\nValidation Loss: 1.3996\nAttribute 1 - Train Acc: 37.75%, Val Acc: 61.00%\nAttribute 2 - Train Acc: 35.00%, Val Acc: 61.00%\nAttribute 3 - Train Acc: 56.12%, Val Acc: 75.50%\nAttribute 4 - Train Acc: 30.25%, Val Acc: 49.50%\nAttribute 5 - Train Acc: 35.00%, Val Acc: 65.00%\nAttribute 6 - Train Acc: 34.50%, Val Acc: 58.00%\nAttribute 7 - Train Acc: 39.25%, Val Acc: 51.00%\nAttribute 8 - Train Acc: 38.88%, Val Acc: 58.50%\nAttribute 9 - Train Acc: 22.50%, Val Acc: 41.00%\nAttribute 10 - Train Acc: 37.88%, Val Acc: 19.50%\nOverall Train Accuracy: 0.00%\nOverall Validation Accuracy: 1.00%\n---------------------------------------------\nnumber of classes for c2 is [5, 7, 4, 9, 5, 4, 5, 6, 10, 3]\n---------------------------------------------\nPreparing data for c3\nInitializing model c3\nTraining model c3\nEpoch 1/1\nTraining Loss: 1.1406\nValidation Loss: 0.9671\nAttribute 1 - Train Acc: 24.50%, Val Acc: 36.00%\nAttribute 2 - Train Acc: 60.00%, Val Acc: 73.50%\nAttribute 3 - Train Acc: 60.00%, Val Acc: 73.50%\nAttribute 4 - Train Acc: 54.50%, Val Acc: 77.50%\nAttribute 5 - Train Acc: 70.00%, Val Acc: 88.50%\nAttribute 6 - Train Acc: 57.62%, Val Acc: 81.00%\nAttribute 7 - Train Acc: 55.50%, Val Acc: 79.00%\nAttribute 8 - Train Acc: 42.50%, Val Acc: 32.50%\nAttribute 9 - Train Acc: 39.38%, Val Acc: 36.00%\nOverall Train Accuracy: 1.88%\nOverall Validation Accuracy: 5.50%\n---------------------------------------------\nnumber of classes for c3 is [14, 3, 3, 3, 3, 3, 3, 4, 3]\n---------------------------------------------\nPreparing data for c4\nInitializing model c4\nTraining model c4\nEpoch 1/1\nTraining Loss: 1.1021\nValidation Loss: 0.8333\nAttribute 1 - Train Acc: 29.75%, Val Acc: 44.50%\nAttribute 2 - Train Acc: 48.38%, Val Acc: 60.50%\nAttribute 3 - Train Acc: 60.38%, Val Acc: 74.50%\nAttribute 4 - Train Acc: 48.62%, Val Acc: 80.50%\nAttribute 5 - Train Acc: 33.12%, Val Acc: 56.50%\nAttribute 6 - Train Acc: 54.50%, Val Acc: 78.00%\nAttribute 7 - Train Acc: 70.75%, Val Acc: 89.50%\nAttribute 8 - Train Acc: 100.00%, Val Acc: 100.00%\nOverall Train Accuracy: 3.12%\nOverall Validation Accuracy: 8.50%\n---------------------------------------------\nnumber of classes for c4 is [8, 4, 4, 4, 7, 4, 3, 1]\n---------------------------------------------\nPreparing data for c5\nInitializing model c5\nTraining model c5\nEpoch 1/1\nTraining Loss: 1.7252\nValidation Loss: 1.5143\nAttribute 1 - Train Acc: 10.62%, Val Acc: 22.50%\nAttribute 2 - Train Acc: 28.25%, Val Acc: 49.00%\nAttribute 3 - Train Acc: 45.00%, Val Acc: 54.00%\nAttribute 4 - Train Acc: 21.38%, Val Acc: 32.00%\nAttribute 5 - Train Acc: 42.62%, Val Acc: 45.50%\nAttribute 6 - Train Acc: 39.62%, Val Acc: 63.00%\nAttribute 7 - Train Acc: 27.62%, Val Acc: 51.50%\nAttribute 8 - Train Acc: 25.12%, Val Acc: 25.00%\nAttribute 9 - Train Acc: 30.12%, Val Acc: 46.00%\nAttribute 10 - Train Acc: 18.50%, Val Acc: 33.50%\nOverall Train Accuracy: 0.12%\nOverall Validation Accuracy: 0.00%\n---------------------------------------------\nnumber of classes for c5 is [13, 5, 3, 8, 3, 4, 7, 5, 5, 7]\n---------------------------------------------\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def get_num_classes_per_attr(df, num_attr_columns, df_name=None):\n    \"\"\"\n    Takes a DataFrame and the number of attribute columns to process.\n    \n    Args:\n    - df: The DataFrame.\n    - num_attr_columns: The number of attribute columns to consider.\n    - df_name: Optional name of the DataFrame, used to apply specific fixes.\n    \n    Returns:\n    - A list containing the number of unique classes for each attribute, adding 1 if NaN values are present.\n    \"\"\"\n    # Select the first 'num_attr_columns' columns from the DataFrame\n    attr_columns = [f'attr_{i}' for i in range(1, num_attr_columns + 1)]\n    \n    # Count the unique values in each attribute column, adding 1 if NaN values are present\n    num_classes_per_attr = [\n        df[attr].nunique() + (1 if df[attr].isnull().any() else 0) for attr in attr_columns\n    ]\n    \n    # Specific fix for df_c3 to correct counting for certain columns\n    if df_name == \"df_c3\":\n        # Force the number of unique classes for attr_5, attr_6, attr_7 to be 3 (based on prior knowledge)\n        num_classes_per_attr[4] = 3\n        num_classes_per_attr[5] = 3\n        num_classes_per_attr[6] = 3\n    \n    return num_classes_per_attr\n\ndef get_all_num_classes_per_attr(df_list, attr_num_list, df_names):\n    \"\"\"\n    Takes a list of DataFrames and a corresponding list of the number of attribute columns for each.\n    \n    Args:\n    - df_list: List of DataFrames.\n    - attr_num_list: List of integers representing the number of attributes for each DataFrame.\n    - df_names: List of DataFrame names, used for specific fixes.\n    \n    Returns:\n    - A list containing the number of unique classes for each attribute for each DataFrame.\n    \"\"\"\n    all_num_classes = []\n    \n    # Iterate over each DataFrame and corresponding number of attribute columns\n    for df, num_attr_columns, df_name in zip(df_list, attr_num_list, df_names):\n        num_classes = get_num_classes_per_attr(df, num_attr_columns, df_name)\n        all_num_classes.append(num_classes)\n    \n    return all_num_classes\n\n# Example usage:\n# Assuming df_c1 to df_c5 are your DataFrames\ndf_list = [df_c1, df_c2, df_c3, df_c4, df_c5]\nattr_num_list = [5, 10, 9, 8, 10]  # Number of attribute columns to consider for each DataFrame\ndf_names = [\"df_c1\", \"df_c2\", \"df_c3\", \"df_c4\", \"df_c5\"]\n\nnum_classes_per_attr_all = get_all_num_classes_per_attr(df_list, attr_num_list, df_names)\n\n# This will give you a list of lists, where each sublist contains the num_classes_per_attr for each DataFrame.\nfor i, num_classes in enumerate(num_classes_per_attr_all):\n    print(f\"num_classes_per_attr for df_c{i + 1}: {num_classes}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:50:30.622700Z","iopub.execute_input":"2024-10-20T20:50:30.623616Z","iopub.status.idle":"2024-10-20T20:50:30.652220Z","shell.execute_reply.started":"2024-10-20T20:50:30.623575Z","shell.execute_reply":"2024-10-20T20:50:30.651215Z"}},"outputs":[{"name":"stdout","text":"num_classes_per_attr for df_c1: [5, 3, 3, 4, 3]\nnum_classes_per_attr for df_c2: [5, 7, 4, 9, 5, 4, 5, 6, 10, 3]\nnum_classes_per_attr for df_c3: [14, 3, 3, 3, 3, 3, 3, 4, 3]\nnum_classes_per_attr for df_c4: [8, 4, 4, 4, 7, 4, 3, 1]\nnum_classes_per_attr for df_c5: [13, 5, 3, 8, 3, 4, 7, 5, 5, 7]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport pickle\n\ndef load_model(model_path, num_classes_per_attr, device):\n    # Initialize the model architecture and load the saved weights\n    model = MultiLabelClassifier(num_classes_per_attr)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n    return model\n\ndef load_label_encoders(encoder_path):\n    with open(encoder_path, 'rb') as f:\n        encoders = pickle.load(f)\n    return encoders\n\n\ndef preprocess_image(image_path, image_size=(224, 224)):\n    # Define image transformations (same as used during training)\n    transform = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize based on ImageNet\n    ])\n    \n    # Open image and apply transformations\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image)\n    image = image.unsqueeze(0)  # Add batch dimension\n    return image\n\ndef inference(image_path, model_path, encoder_path, num_classes_per_attr, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    # Load the model and encoders\n    model = load_model(model_path, num_classes_per_attr, device)\n    label_encoders = load_label_encoders(encoder_path)\n\n    # Preprocess the image\n    image = preprocess_image(image_path).to(device)\n\n    # Perform inference\n    with torch.no_grad():\n        outputs = model(image)\n\n    # Decode predictions\n    predicted_labels = []\n    for i, output in enumerate(outputs):\n        _, predicted = torch.max(output, 1)\n\n        # Attribute name should match the encoder dictionary keys like 'attr_1', 'attr_2', etc.\n        attr_name = f'attr_{i+1}'\n        if attr_name in label_encoders.encoders:\n            decoded_label = label_encoders.encoders[attr_name].inverse_transform([predicted.item()])[0]\n            predicted_labels.append(decoded_label)\n        else:\n            raise KeyError(f\"Encoder for {attr_name} not found in the loaded label encoders.\")\n    \n    return predicted_labels\n\n\n# Example usage:\nimage_path = \"/kaggle/input/visual-taxonomy/train_images/000001.jpg\"\nmodel_path = \"best_model_c1.pth\"\nencoder_path = \"/kaggle/working/label_encoders_c1.pkl\"\nnum_classes_per_attr = [5, 3, 3, 4, 3]\npredictions = inference(image_path, model_path, encoder_path, num_classes_per_attr)\nprint(\"Predicted labels:\", predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:08:37.635729Z","iopub.execute_input":"2024-10-20T20:08:37.636111Z","iopub.status.idle":"2024-10-20T20:08:38.170482Z","shell.execute_reply.started":"2024-10-20T20:08:37.636072Z","shell.execute_reply":"2024-10-20T20:08:38.169446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport pickle\nimport csv\n\n# Map categories to corresponding attribute columns (e.g., c1, c2, c3)\ncategory_to_attributes = {\n    'Men Tshirts': 'c1',\n    'Sarees': 'c2',\n    'Kurtis': 'c3',\n    'Women Tshirts': 'c4',\n    'Women Tops & Tunics': 'c5',\n}\n\n# Dummy value for missing attributes\nDUMMY_VALUE = \"dummy_value\"\n\ndef load_model(model_path, num_classes_per_attr, device):\n    model = MultiLabelClassifier(num_classes_per_attr)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n    return model\n\ndef load_label_encoders(encoder_path):\n    with open(encoder_path, 'rb') as f:\n        encoders = pickle.load(f)\n    return encoders\n\ndef preprocess_image(image_path, image_size=(224, 224)):\n    transform = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image)\n    image = image.unsqueeze(0)  # Add batch dimension\n    return image\n\ndef inference(image_path, model, label_encoders, num_classes_per_attr, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    image = preprocess_image(image_path).to(device)\n    with torch.no_grad():\n        outputs = model(image)\n\n    predicted_labels = []\n    for i, output in enumerate(outputs):\n        _, predicted = torch.max(output, 1)\n        attr_name = f'attr_{i+1}'\n        if attr_name in label_encoders.encoders:\n            decoded_label = label_encoders.encoders[attr_name].inverse_transform([predicted.item()])[0]\n            predicted_labels.append(decoded_label)\n        else:\n            predicted_labels.append(DUMMY_VALUE)\n    \n    return predicted_labels\n\ndef make_predictions_for_dataset(df, model_paths, encoder_paths, output_path, image_dir, num_classes_per_attr_list, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \n    all_models = []\n    all_label_encoders = []\n    \n    # Load models and encoders for each attribute (c1 to c5)\n    for model_path, encoder_path, num_classes_per_attr in zip(model_paths, encoder_paths, num_classes_per_attr_list):\n        model = load_model(model_path, num_classes_per_attr, device)\n        label_encoders = load_label_encoders(encoder_path)\n        all_models.append(model)\n        all_label_encoders.append(label_encoders)\n    \n    all_predictions = []\n    \n    for idx, row in df.iterrows():\n        category = row['Category']\n        attribute_key = category_to_attributes.get(category, None)\n\n        if attribute_key:\n            # Determine which model and encoder to use based on the category\n            attribute_idx = int(attribute_key[1]) - 1  # Example: 'c1' -> index 0, 'c2' -> index 1, etc.\n            model = all_models[attribute_idx]\n            label_encoders = all_label_encoders[attribute_idx]\n            num_classes_per_attr = num_classes_per_attr_list[attribute_idx]\n\n            image_path = f\"{image_dir}/{str(row['id']).zfill(6)}.jpg\"  # Assuming image names follow a pattern with id\n            \n            try:\n                predictions = inference(image_path, model, label_encoders, num_classes_per_attr, device)\n            except Exception as e:\n                print(f\"Error with image {image_path}: {e}\")\n                predictions = [DUMMY_VALUE] * len(num_classes_per_attr)  # Fallback in case of error\n        else:\n            predictions = [DUMMY_VALUE] * len(num_classes_per_attr_list[0])  # Handle if category has no mapping\n            \n        # Pad the predictions to ensure each row has 10 attributes\n        while len(predictions) < 10:\n            predictions.append(DUMMY_VALUE)\n        \n        all_predictions.append([row['id']] + predictions)\n\n    # Save predictions to CSV\n    with open(output_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        header = ['id'] + [f'c{i+1}' for i in range(10)]  # Fixed number of attributes as 10\n        writer.writerow(header)\n        writer.writerows(all_predictions)\n\n    print(f\"Predictions saved to {output_path}\")\n\n# Example usage\ndataset_path = '/kaggle/input/visual-taxonomy/test.csv'  # Path to your dataset\nmodel_paths = ['/kaggle/working/best_model_c1.pth', '/kaggle/working/best_model_c2.pth', '/kaggle/working/best_model_c3.pth', '/kaggle/working/best_model_c4.pth', '/kaggle/working/best_model_c5.pth']\nencoder_paths = ['/kaggle/working/label_encoders_c1.pkl', '/kaggle/working/label_encoders_c2.pkl', '/kaggle/working/label_encoders_c3.pkl', '/kaggle/working/label_encoders_c4.pkl', '/kaggle/working/label_encoders_c5.pkl']\noutput_path = '/kaggle/working/output_predictions.csv'  # Path to save predictions\nimage_dir = '/kaggle/input/visual-taxonomy/test_images'  # Directory containing images\nnum_classes_per_attr_list = [\n    [5, 3, 3, 4, 3],  # For c1\n    [5, 7, 4, 9, 5, 4, 5, 6, 10, 3],  # For c2\n    [14, 3, 3, 3, 3, 3, 3, 4, 3],  # For c3\n    [8, 4, 4, 4, 7, 4, 3, 1],  # For c4\n    [13, 5, 3, 8, 3, 4, 7, 5, 5, 7],  # For c5\n]\n\ntest_df = pd.read_csv(dataset_path)\n# test_df = test_df[:300]\n\nmake_predictions_for_dataset(test_df, model_paths, encoder_paths, output_path, image_dir, num_classes_per_attr_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T20:50:48.775194Z","iopub.execute_input":"2024-10-20T20:50:48.775889Z","iopub.status.idle":"2024-10-20T20:51:00.177570Z","shell.execute_reply.started":"2024-10-20T20:50:48.775849Z","shell.execute_reply":"2024-10-20T20:51:00.176545Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to /kaggle/working/output_predictions.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}